{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "In this notebook, I'll share an image clacification approach for given spectrograms.  \n",
    "\n",
    "I tried several experiments, but didn't obtain good results :(\n",
    "\n",
    "\n",
    "* **version 1**: naive approach\n",
    "* **version 2**: For comparing with [Chris's EfficientNetB2 Starter](https://www.kaggle.com/code/cdeotte/efficientnetb2-starter-lb-0-57), I added **log transform** and **LR scheduling**.\n",
    "\n",
    "## Experimental Settings\n",
    "\n",
    "### model\n",
    "* backbone: resnet34d (use the pretrained model provided by [timm](https://github.com/huggingface/pytorch-image-models))\n",
    "* head classifier: one linear layer\n",
    "* num of input channels: 1\n",
    "\n",
    "### data augmentationÂ¶\n",
    "* implemented by [albumentations](https://albumentations.ai/)\n",
    "* Train\n",
    "    * Resize\n",
    "* Val, Test\n",
    "    * Resize\n",
    "    \n",
    "### learning settings\n",
    "* CV Strategy: Stratified Group KFold (K=5)\n",
    "    * y: `expert_consensus`\n",
    "    * group: `patient_id`\n",
    "* max epochs: 9\n",
    "* data:\n",
    "    * input image size: 1x512x512\n",
    "    * batch size: 32\n",
    "* loss: [KLDivLoss](https://pytorch.org/docs/stable/generated/torch.nn.KLDivLoss.html)\n",
    "* optimizer: AdamW\n",
    "    * learning rate: 1.0e-03\n",
    "    * weight decay: 1.0e-02\n",
    "    \n",
    "* lr scheduler: OneCycleLR\n",
    "    * max lr: 1.0e-03\n",
    "    * min lr: 1.0e-04\n",
    "    \n",
    "### NOTE: I normalized spectrograms per image\n",
    "```python\n",
    "img = np.load(path)  # shape: (Hz, Time) = (400, 300)\n",
    "eps = 1e-6\n",
    "img_mean = img.mean(axis=(0, 1))\n",
    "img = img - img_mean\n",
    "img_std = img.std(axis=(0, 1))\n",
    "img = img / (img_std + eps)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import gc\n",
    "import copy\n",
    "import yaml\n",
    "import random\n",
    "import shutil\n",
    "from time import time\n",
    "import typing as tp\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.cuda import amp\n",
    "\n",
    "import timm\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ROOT = Path.cwd().parent\n",
    "INPUT = ROOT / \"input\"\n",
    "OUTPUT = ROOT / \"output\"\n",
    "SRC = ROOT / \"src\"\n",
    "\n",
    "DATA = INPUT / \"hms-harmful-brain-activity-classification\"\n",
    "TRAIN_SPEC = DATA / \"train_spectrograms\"\n",
    "TEST_SPEC = DATA / \"test_spectrograms\"\n",
    "\n",
    "TMP = ROOT / \"tmp\"\n",
    "TRAIN_SPEC_SPLIT = TMP / \"train_spectrograms_split\"\n",
    "TEST_SPEC_SPLIT = TMP / \"test_spectrograms_split\"\n",
    "TMP.mkdir(exist_ok=True)\n",
    "TRAIN_SPEC_SPLIT.mkdir(exist_ok=True)\n",
    "TEST_SPEC_SPLIT.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "RANDAM_SEED = 1086\n",
    "CLASSES = [\"seizure_vote\", \"lpd_vote\", \"gpd_vote\", \"lrda_vote\", \"grda_vote\", \"other_vote\"]\n",
    "N_CLASSES = len(CLASSES)\n",
    "FOLDS = [0, 1, 2, 3, 4]\n",
    "N_FOLDS = len(FOLDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data, Split Folds, Split Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106800, 15)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(DATA / \"train.csv\")\n",
    "\n",
    "# convert vote to probability\n",
    "train[CLASSES] /= train[CLASSES].sum(axis=1).values[:, None]\n",
    "\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-14T00:22:27.085297Z",
     "iopub.status.busy": "2024-01-14T00:22:27.084935Z",
     "iopub.status.idle": "2024-01-14T00:22:27.093145Z",
     "shell.execute_reply": "2024-01-14T00:22:27.091394Z",
     "shell.execute_reply.started": "2024-01-14T00:22:27.085268Z"
    }
   },
   "source": [
    "### NOTE: I used the **first** `spectrogram_sub_id` for each `spectrogram_id` in order to train model faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11138, 16)\n"
     ]
    }
   ],
   "source": [
    "train = train.groupby(\"spectrogram_id\").head(1).reset_index(drop=True)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sgkf = StratifiedGroupKFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDAM_SEED)\n",
    "\n",
    "train[\"fold\"] = -1\n",
    "\n",
    "for fold_id, (_, val_idx) in enumerate(\n",
    "    sgkf.split(train, y=train[\"expert_consensus\"], groups=train[\"patient_id\"])\n",
    "):\n",
    "    train.loc[val_idx, \"fold\"] = fold_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seizure_vote</th>\n",
       "      <th>lpd_vote</th>\n",
       "      <th>gpd_vote</th>\n",
       "      <th>lrda_vote</th>\n",
       "      <th>grda_vote</th>\n",
       "      <th>other_vote</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>407.878970</td>\n",
       "      <td>240.847820</td>\n",
       "      <td>262.474513</td>\n",
       "      <td>142.304068</td>\n",
       "      <td>286.407590</td>\n",
       "      <td>800.087038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>360.427388</td>\n",
       "      <td>231.931854</td>\n",
       "      <td>193.738000</td>\n",
       "      <td>173.763906</td>\n",
       "      <td>333.566517</td>\n",
       "      <td>1166.572336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>441.934721</td>\n",
       "      <td>328.255479</td>\n",
       "      <td>237.291923</td>\n",
       "      <td>163.192668</td>\n",
       "      <td>355.493987</td>\n",
       "      <td>926.831222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>425.685980</td>\n",
       "      <td>195.568155</td>\n",
       "      <td>182.017264</td>\n",
       "      <td>148.850582</td>\n",
       "      <td>259.828026</td>\n",
       "      <td>864.049993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>392.391708</td>\n",
       "      <td>234.916737</td>\n",
       "      <td>120.355588</td>\n",
       "      <td>129.112045</td>\n",
       "      <td>258.598367</td>\n",
       "      <td>873.625556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      seizure_vote    lpd_vote    gpd_vote   lrda_vote   grda_vote  \\\n",
       "fold                                                                 \n",
       "0       407.878970  240.847820  262.474513  142.304068  286.407590   \n",
       "1       360.427388  231.931854  193.738000  173.763906  333.566517   \n",
       "2       441.934721  328.255479  237.291923  163.192668  355.493987   \n",
       "3       425.685980  195.568155  182.017264  148.850582  259.828026   \n",
       "4       392.391708  234.916737  120.355588  129.112045  258.598367   \n",
       "\n",
       "       other_vote  \n",
       "fold               \n",
       "0      800.087038  \n",
       "1     1166.572336  \n",
       "2      926.831222  \n",
       "3      864.049993  \n",
       "4      873.625556  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(\"fold\")[CLASSES].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split sepectogram files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e24966ddda7b4433b89ed68dbd8b1dfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for spec_id, df in tqdm(train.groupby(\"spectrogram_id\")):\n",
    "    spec = pd.read_parquet(TRAIN_SPEC / f\"{spec_id}.parquet\")\n",
    "    \n",
    "    spec_arr = spec.fillna(0).values[:, 1:].T.astype(\"float32\")  # (Hz, Time) = (400, 300)\n",
    "    \n",
    "    for spec_offset, label_id in df[\n",
    "        [\"spectrogram_label_offset_seconds\", \"label_id\"]\n",
    "    ].astype(int).values:\n",
    "        spec_offset = spec_offset // 2\n",
    "        split_spec_arr = spec_arr[:, spec_offset: spec_offset + 300]\n",
    "        np.save(TRAIN_SPEC_SPLIT / f\"{label_id}.npy\" , split_spec_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difinition, Model, Dataset, Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "_kg_hide-input": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HMSHBACSpecModel(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            model_name: str,\n",
    "            pretrained: bool,\n",
    "            in_channels: int,\n",
    "            num_classes: int,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(\n",
    "            model_name=model_name, pretrained=pretrained,\n",
    "            num_classes=num_classes, in_chans=in_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.model(x)      \n",
    "\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#timm.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "_kg_hide-input": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "FilePath = tp.Union[str, Path]\n",
    "Label = tp.Union[int, float, np.ndarray]\n",
    "\n",
    "class HMSHBACSpecDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        image_paths: tp.Sequence[FilePath],\n",
    "        labels: tp.Sequence[Label],\n",
    "        transform: A.Compose,\n",
    "    ):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        img_path = self.image_paths[index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        img = np.load(img_path)  # shape: (Hz, Time) = (400, 300)\n",
    "        \n",
    "        # log transform\n",
    "        img = np.clip(img,np.exp(-4), np.exp(8))\n",
    "        img = np.log(img)\n",
    "        \n",
    "        # normalize per image\n",
    "        eps = 1e-6\n",
    "        img_mean = img.mean(axis=(0, 1))\n",
    "        img = img - img_mean\n",
    "        img_std = img.std(axis=(0, 1))\n",
    "        img = img / (img_std + eps)\n",
    "\n",
    "        img = img[..., None] # shape: (Hz, Time) -> (Hz, Time, Channel)\n",
    "        img = self._apply_transform(img)\n",
    "\n",
    "        return {\"data\": img, \"target\": label}\n",
    "\n",
    "    def _apply_transform(self, img: np.ndarray):\n",
    "        \"\"\"apply transform to image and mask\"\"\"\n",
    "        transformed = self.transform(image=img)\n",
    "        img = transformed[\"image\"]\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "_kg_hide-input": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class KLDivLossWithLogits(nn.KLDivLoss):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(reduction=\"batchmean\")\n",
    "\n",
    "    def forward(self, y, t):\n",
    "        y = nn.functional.log_softmax(y,  dim=1)\n",
    "        loss = super().forward(y, t)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "class KLDivLossWithLogitsForVal(nn.KLDivLoss):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\"\"\"\n",
    "        super().__init__(reduction=\"batchmean\")\n",
    "        self.log_prob_list  = []\n",
    "        self.label_list = []\n",
    "\n",
    "    def forward(self, y, t):\n",
    "        y = nn.functional.log_softmax(y, dim=1)\n",
    "        self.log_prob_list.append(y.numpy())\n",
    "        self.label_list.append(t.numpy())\n",
    "        \n",
    "    def compute(self):\n",
    "        log_prob = np.concatenate(self.log_prob_list, axis=0)\n",
    "        label = np.concatenate(self.label_list, axis=0)\n",
    "        final_metric = super().forward(\n",
    "            torch.from_numpy(log_prob),\n",
    "            torch.from_numpy(label)\n",
    "        ).item()\n",
    "        self.log_prob_list = []\n",
    "        self.label_list = []\n",
    "        \n",
    "        return final_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    model_name = \"efficientnet_b2\"\n",
    "    img_size = 512\n",
    "    max_epoch = 9\n",
    "    batch_size = 16\n",
    "    lr = 1.0e-03\n",
    "    weight_decay = 1.0e-02\n",
    "    es_patience =  5\n",
    "    seed = 1086\n",
    "    deterministic = True\n",
    "    enable_amp = False\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_random_seed(seed: int = 42, deterministic: bool = False):\n",
    "    \"\"\"Set seeds\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    # torch.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = deterministic  # type: ignore\n",
    "    \n",
    "def to_device(\n",
    "    tensors: tp.Union[tp.Tuple[torch.Tensor], tp.Dict[str, torch.Tensor]],\n",
    "    device: torch.device, *args, **kwargs\n",
    "):\n",
    "    if isinstance(tensors, tuple):\n",
    "        return (t.to(device, *args, **kwargs) for t in tensors)\n",
    "    elif isinstance(tensors, dict):\n",
    "        return {\n",
    "            k: t.to(device, *args, **kwargs) for k, t in tensors.items()}\n",
    "    else:\n",
    "        return tensors.to(device, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_path_label(val_fold, train_all: pd.DataFrame):\n",
    "    \"\"\"Get file path and target info.\"\"\"\n",
    "    \n",
    "    train_idx = train_all[train_all[\"fold\"] != val_fold].index.values\n",
    "    val_idx   = train_all[train_all[\"fold\"] == val_fold].index.values\n",
    "    img_paths = []\n",
    "    labels = train_all[CLASSES].values\n",
    "    for label_id in train_all[\"label_id\"].values:\n",
    "        img_path = TRAIN_SPEC_SPLIT / f\"{label_id}.npy\"\n",
    "        img_paths.append(img_path)\n",
    "\n",
    "    train_data = {\n",
    "        \"image_paths\": [img_paths[idx] for idx in train_idx],\n",
    "        \"labels\": [labels[idx].astype(\"float32\") for idx in train_idx]}\n",
    "\n",
    "    val_data = {\n",
    "        \"image_paths\": [img_paths[idx] for idx in val_idx],\n",
    "        \"labels\": [labels[idx].astype(\"float32\") for idx in val_idx]}\n",
    "    \n",
    "    return train_data, val_data, train_idx, val_idx\n",
    "\n",
    "\n",
    "def get_transforms(CFG):\n",
    "    train_transform = A.Compose([\n",
    "        A.Resize(p=1.0, height=CFG.img_size, width=CFG.img_size),\n",
    "        ToTensorV2(p=1.0)\n",
    "    ])\n",
    "    val_transform = A.Compose([\n",
    "        A.Resize(p=1.0, height=CFG.img_size, width=CFG.img_size),\n",
    "        ToTensorV2(p=1.0)\n",
    "    ])\n",
    "    return train_transform, val_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_one_fold(CFG, val_fold, train_all, output_path):\n",
    "    \"\"\"Main\"\"\"\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    set_random_seed(CFG.seed, deterministic=CFG.deterministic)\n",
    "    device = torch.device(CFG.device)\n",
    "    \n",
    "    train_path_label, val_path_label, _, _ = get_path_label(val_fold, train_all)\n",
    "    train_transform, val_transform = get_transforms(CFG)\n",
    "    \n",
    "    train_dataset = HMSHBACSpecDataset(**train_path_label, transform=train_transform)\n",
    "    val_dataset = HMSHBACSpecDataset(**val_path_label, transform=val_transform)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=CFG.batch_size, num_workers=4, shuffle=True, drop_last=True)\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=CFG.batch_size, num_workers=4, shuffle=False, drop_last=False)\n",
    "    \n",
    "    model = HMSHBACSpecModel(\n",
    "        model_name=CFG.model_name, pretrained=True, num_classes=6, in_channels=1)\n",
    "    model.to(device)\n",
    "    \n",
    "    optimizer = optim.AdamW(params=model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
    "    scheduler = lr_scheduler.OneCycleLR(\n",
    "        optimizer=optimizer, epochs=CFG.max_epoch,\n",
    "        pct_start=0.0, steps_per_epoch=len(train_loader),\n",
    "        max_lr=CFG.lr, div_factor=25, final_div_factor=4.0e-01\n",
    "    )\n",
    "    \n",
    "    loss_func = KLDivLossWithLogits()\n",
    "    loss_func.to(device)\n",
    "    loss_func_val = KLDivLossWithLogitsForVal()\n",
    "    \n",
    "    use_amp = CFG.enable_amp\n",
    "    scaler = amp.GradScaler(enabled=use_amp)\n",
    "    \n",
    "    best_val_loss = 1.0e+09\n",
    "    best_epoch = 0\n",
    "    train_loss = 0\n",
    "    \n",
    "    for epoch in range(1, CFG.max_epoch + 1):\n",
    "        epoch_start = time()\n",
    "        model.train()\n",
    "        for batch in tqdm(train_loader):\n",
    "            batch = to_device(batch, device)\n",
    "            x, t = batch[\"data\"], batch[\"target\"]\n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "            with amp.autocast(use_amp):\n",
    "                y = model(x)\n",
    "                loss = loss_func(y, t)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        train_loss /= len(train_loader)\n",
    "            \n",
    "        model.eval()\n",
    "        for batch in val_loader:\n",
    "            x, t = batch[\"data\"], batch[\"target\"]\n",
    "            x = to_device(x, device)\n",
    "            with torch.no_grad(), amp.autocast(use_amp):\n",
    "                y = model(x)\n",
    "            y = y.detach().cpu().to(torch.float32)\n",
    "            loss_func_val(y, t)\n",
    "        val_loss = loss_func_val.compute()        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_epoch = epoch\n",
    "            best_val_loss = val_loss\n",
    "            # print(\"save model\")\n",
    "            torch.save(model.state_dict(), str(output_path / f'snapshot_epoch_{epoch}.pth'))\n",
    "        \n",
    "        elapsed_time = time() - epoch_start\n",
    "        print(\n",
    "            f\"[epoch {epoch}] train loss: {train_loss: .6f}, val loss: {val_loss: .6f}, elapsed_time: {elapsed_time: .3f}\")\n",
    "        \n",
    "        if epoch - best_epoch > CFG.es_patience:\n",
    "            print(\"Early Stopping!\")\n",
    "            break\n",
    "            \n",
    "        train_loss = 0\n",
    "            \n",
    "    return val_fold, best_epoch, best_val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list = []\n",
    "for fold_id in FOLDS:\n",
    "    output_path = Path(f\"fold{fold_id}\")\n",
    "    output_path.mkdir(exist_ok=True)\n",
    "    print(f\"[fold{fold_id}]\")\n",
    "    score_list.append(train_one_fold(CFG, fold_id, train, output_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference Out Of Fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-16T08:49:22.108612Z",
     "iopub.status.idle": "2024-01-16T08:49:22.109108Z",
     "shell.execute_reply": "2024-01-16T08:49:22.108883Z",
     "shell.execute_reply.started": "2024-01-16T08:49:22.108858Z"
    }
   },
   "outputs": [],
   "source": [
    "print(score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-16T08:49:22.110692Z",
     "iopub.status.idle": "2024-01-16T08:49:22.111017Z",
     "shell.execute_reply": "2024-01-16T08:49:22.110869Z",
     "shell.execute_reply.started": "2024-01-16T08:49:22.110854Z"
    }
   },
   "outputs": [],
   "source": [
    "best_log_list = []\n",
    "for (fold_id, best_epoch, _) in score_list:\n",
    "    \n",
    "    exp_dir_path = Path(f\"fold{fold_id}\")\n",
    "    best_model_path = exp_dir_path / f\"snapshot_epoch_{best_epoch}.pth\"\n",
    "    copy_to = f\"./best_model_fold{fold_id}.pth\"\n",
    "    shutil.copy(best_model_path, copy_to)\n",
    "    \n",
    "    for p in exp_dir_path.glob(\"*.pth\"):\n",
    "        p.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference OOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-16T08:49:22.112377Z",
     "iopub.status.idle": "2024-01-16T08:49:22.112839Z",
     "shell.execute_reply": "2024-01-16T08:49:22.112631Z",
     "shell.execute_reply.started": "2024-01-16T08:49:22.112609Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_inference_loop(model, loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    pred_list = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader):\n",
    "            x = to_device(batch[\"data\"], device)\n",
    "            y = model(x)\n",
    "            pred_list.append(y.softmax(dim=1).detach().cpu().numpy())\n",
    "        \n",
    "    pred_arr = np.concatenate(pred_list)\n",
    "    del pred_list\n",
    "    return pred_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-16T08:49:22.114326Z",
     "iopub.status.idle": "2024-01-16T08:49:22.114698Z",
     "shell.execute_reply": "2024-01-16T08:49:22.114513Z",
     "shell.execute_reply.started": "2024-01-16T08:49:22.114496Z"
    }
   },
   "outputs": [],
   "source": [
    "label_arr = train[CLASSES].values\n",
    "oof_pred_arr = np.zeros((len(train), N_CLASSES))\n",
    "score_list = []\n",
    "\n",
    "for fold_id in range(N_FOLDS):\n",
    "    print(f\"\\n[fold {fold_id}]\")\n",
    "    device = torch.device(CFG.device)\n",
    "\n",
    "    # # get_dataloader\n",
    "    _, val_path_label, _, val_idx = get_path_label(fold_id, train)\n",
    "    _, val_transform = get_transforms(CFG)\n",
    "    val_dataset = HMSHBACSpecDataset(**val_path_label, transform=val_transform)\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=CFG.batch_size, num_workers=4, shuffle=False, drop_last=False)\n",
    "    \n",
    "    # # get model\n",
    "    model_path = f\"./best_model_fold{fold_id}.pth\"\n",
    "    model = HMSHBACSpecModel(\n",
    "        model_name=CFG.model_name, pretrained=False, num_classes=6, in_channels=1)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    \n",
    "    # # inference\n",
    "    val_pred = run_inference_loop(model, val_loader, device)\n",
    "    oof_pred_arr[val_idx] = val_pred\n",
    "    \n",
    "    del val_idx, val_path_label\n",
    "    del model, val_loader\n",
    "    torch.cpu.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate OOF score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-16T08:49:22.116578Z",
     "iopub.status.idle": "2024-01-16T08:49:22.116927Z",
     "shell.execute_reply": "2024-01-16T08:49:22.116777Z",
     "shell.execute_reply.started": "2024-01-16T08:49:22.116761Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/kaggle/input/kaggle-kl-div')\n",
    "from kaggle_kl_div import score\n",
    "\n",
    "true = train[[\"label_id\"] + CLASSES].copy()\n",
    "\n",
    "oof = pd.DataFrame(oof_pred_arr, columns=CLASSES)\n",
    "oof.insert(0, \"label_id\", train[\"label_id\"])\n",
    "\n",
    "cv_score = score(solution=true, submission=oof, row_id_column_name='label_id')\n",
    "print('CV Score KL-Div for ResNet34d',cv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EOF"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 7469972,
     "sourceId": 59093,
     "sourceType": "competition"
    },
    {
     "datasetId": 4297749,
     "sourceId": 7392733,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30636,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
