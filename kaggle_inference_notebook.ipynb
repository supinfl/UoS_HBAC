{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97ae8bdf",
   "metadata": {
    "_cell_guid": "59e4da84-b0a2-4db0-a08c-f66119727ca8",
    "_uuid": "e61058a2-56c9-49a7-929d-9694cc0359f9",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-04-08T21:00:10.575719Z",
     "iopub.status.busy": "2024-04-08T21:00:10.575333Z",
     "iopub.status.idle": "2024-04-08T21:00:22.550233Z",
     "shell.execute_reply": "2024-04-08T21:00:22.548881Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 11.98445,
     "end_time": "2024-04-08T21:00:22.552739",
     "exception": false,
     "start_time": "2024-04-08T21:00:10.568289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 0 GPU(s)\n"
     ]
    }
   ],
   "source": [
    "import albumentations as A\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from glob import glob\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, List\n",
    "\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "from skimage.transform import resize\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "import torch.nn.functional as F\n",
    "import logging\n",
    "import functools\n",
    "import pywt\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Using', torch.cuda.device_count(), 'GPU(s)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23ee45b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T21:00:22.565075Z",
     "iopub.status.busy": "2024-04-08T21:00:22.563867Z",
     "iopub.status.idle": "2024-04-08T21:00:22.572358Z",
     "shell.execute_reply": "2024-04-08T21:00:22.571264Z"
    },
    "papermill": {
     "duration": 0.016921,
     "end_time": "2024-04-08T21:00:22.574698",
     "exception": false,
     "start_time": "2024-04-08T21:00:22.557777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class config:\n",
    "    AMP = True\n",
    "    BATCH_SIZE_TRAIN = 8\n",
    "    BATCH_SIZE_VALID = 8\n",
    "    BATCH_SIZE = 8\n",
    "    EPOCHS = 4\n",
    "    FOLDS = 5\n",
    "    FREEZE = False\n",
    "    GRADIENT_ACCUMULATION_STEPS = 1\n",
    "    MAX_GRAD_NORM = 1e7\n",
    "    MODEL = \"efficientnet_b2\"\n",
    "    NUM_FROZEN_LAYERS = 39\n",
    "    NUM_WORKERS = 0 # multiprocessing.cpu_count()\n",
    "    PRINT_FREQ = 20\n",
    "    SEED = 20\n",
    "    TRAIN_FULL_DATA = False\n",
    "    VISUALIZE = False\n",
    "    WEIGHT_DECAY = 0.01\n",
    "    \n",
    "    \n",
    "class paths:\n",
    "    # OUTPUT_DIR = \"/kaggle/working/\"\n",
    "    # PRE_LOADED_EEGS = '/kaggle/input/brain-eeg-spectrograms/eeg_specs.npy'\n",
    "    # PRE_LOADED_SPECTOGRAMS = '/kaggle/input/brain-spectrograms/specs.npy'\n",
    "    # TRAIN_CSV = \"/kaggle/input/hms-harmful-brain-activity-classification/train.csv\"\n",
    "    # TRAIN_EEGS = \"/kaggle/input/brain-eeg-spectrograms/EEG_Spectrograms/\"\n",
    "    # TRAIN_SPECTOGRAMS = \"/kaggle/input/hms-harmful-brain-activity-classification/train_spectrograms/\"\n",
    "    ROOT = Path.cwd()\n",
    "    INPUT = ROOT / \"input\"\n",
    "#     OUTPUT_DIR = ROOT / \"output\"\n",
    "    OUTPUT_DIR = Path('/kaggle/input/efb2-epoch4/output')\n",
    "#     DATA = Path(\"./original_data\")\n",
    "    DATA = Path(\"/kaggle/input/hms-harmful-brain-activity-classification\")\n",
    "\n",
    "    PRE_LOADED_EEGS = './kaggle/input/brain-eeg-spectrograms/eeg_specs.npy'\n",
    "    PRE_LOADED_SPECTROGRAMS = './kaggle/input/brain-spectrograms/specs.npy'\n",
    "    PRE_LOADED_Wavelets = './kaggle/input/brain-wavelets/specs.npy'\n",
    "\n",
    "\n",
    "    \n",
    "    TRAIN_SPECTROGRAMS = DATA / \"train_spectrograms\"\n",
    "    TRAIN_EEGS = DATA / \"train_eegs\"\n",
    "    TRAIN_CSV = DATA / \"train.csv\"\n",
    "    TEST_CSV = DATA / \"test.csv\"\n",
    "    TEST_SPECTROGRAMS = DATA / \"test_spectrograms\"\n",
    "    TEST_EEGS = DATA / \"test_eegs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "866940ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T21:00:22.585541Z",
     "iopub.status.busy": "2024-04-08T21:00:22.585181Z",
     "iopub.status.idle": "2024-04-08T21:00:22.592113Z",
     "shell.execute_reply": "2024-04-08T21:00:22.590893Z"
    },
    "papermill": {
     "duration": 0.014779,
     "end_time": "2024-04-08T21:00:22.594137",
     "exception": false,
     "start_time": "2024-04-08T21:00:22.579358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_filename = paths.ROOT/'new_version_inference_record.log'\n",
    "\n",
    "logging.basicConfig(filename=log_filename, level=logging.INFO,\n",
    "                    format='%(asctime)s %(levelname)s %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "def log_time(func):\n",
    "    \"\"\"warpper for logging running time\"\"\"\n",
    "\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        logging.info(f\"{func.__name__} took {end_time - start_time:.4f} seconds.\")\n",
    "        print(f\"{func.__name__} took {end_time - start_time:.4f} seconds.\")\n",
    "        return result\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5f5e46f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T21:00:22.605305Z",
     "iopub.status.busy": "2024-04-08T21:00:22.604898Z",
     "iopub.status.idle": "2024-04-08T21:00:22.620273Z",
     "shell.execute_reply": "2024-04-08T21:00:22.619417Z"
    },
    "papermill": {
     "duration": 0.023563,
     "end_time": "2024-04-08T21:00:22.622437",
     "exception": false,
     "start_time": "2024-04-08T21:00:22.598874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s: float):\n",
    "    \"Convert to minutes.\"\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since: float, percent: float):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "\n",
    "def plot_spectrogram(spectrogram_path: str):\n",
    "    \"\"\"\n",
    "    Source: https://www.kaggle.com/code/mvvppp/hms-eda-and-domain-journey\n",
    "    Visualize spectogram recordings from a parquet file.\n",
    "    :param spectrogram_path: path to the spectogram parquet.\n",
    "    \"\"\"\n",
    "    sample_spect = pd.read_parquet(spectrogram_path)\n",
    "    \n",
    "    split_spect = {\n",
    "        \"LL\": sample_spect.filter(regex='^LL', axis=1),\n",
    "        \"RL\": sample_spect.filter(regex='^RL', axis=1),\n",
    "        \"RP\": sample_spect.filter(regex='^RP', axis=1),\n",
    "        \"LP\": sample_spect.filter(regex='^LP', axis=1),\n",
    "    }\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 12))\n",
    "    axes = axes.flatten()\n",
    "    label_interval = 5\n",
    "    for i, split_name in enumerate(split_spect.keys()):\n",
    "        ax = axes[i]\n",
    "        img = ax.imshow(np.log(split_spect[split_name]).T, cmap='viridis', aspect='auto', origin='lower')\n",
    "        cbar = fig.colorbar(img, ax=ax)\n",
    "        cbar.set_label('Log(Value)')\n",
    "        ax.set_title(split_name)\n",
    "        ax.set_ylabel(\"Frequency (Hz)\")\n",
    "        ax.set_xlabel(\"Time\")\n",
    "\n",
    "        ax.set_yticks(np.arange(len(split_spect[split_name].columns)))\n",
    "        ax.set_yticklabels([column_name[3:] for column_name in split_spect[split_name].columns])\n",
    "        frequencies = [column_name[3:] for column_name in split_spect[split_name].columns]\n",
    "        ax.set_yticks(np.arange(0, len(split_spect[split_name].columns), label_interval))\n",
    "        ax.set_yticklabels(frequencies[::label_interval])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "@log_time   \n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed) \n",
    "\n",
    "   \n",
    "def sep():\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "840a7667",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T21:00:22.633541Z",
     "iopub.status.busy": "2024-04-08T21:00:22.632927Z",
     "iopub.status.idle": "2024-04-08T21:00:22.658134Z",
     "shell.execute_reply": "2024-04-08T21:00:22.656951Z"
    },
    "papermill": {
     "duration": 0.033147,
     "end_time": "2024-04-08T21:00:22.660363",
     "exception": false,
     "start_time": "2024-04-08T21:00:22.627216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, df: pd.DataFrame, config,\n",
    "        augment: bool = False, mode: str = 'train',\n",
    "        specs: Dict[int, np.ndarray] = None,\n",
    "        eeg_specs: Dict[int, np.ndarray] = None,\n",
    "        wavelets_spectrograms: Dict[int, np.ndarray] = None\n",
    "    ): \n",
    "        self.df = df\n",
    "        self.config = config\n",
    "        self.batch_size = self.config.BATCH_SIZE_TRAIN\n",
    "        self.augment = augment\n",
    "        self.mode = mode\n",
    "        self.spectrograms = specs if specs is not None else {}\n",
    "        self.eeg_spectrograms = eeg_specs if eeg_specs is not None else {}\n",
    "        self.wavelets_spectrograms = wavelets_spectrograms if wavelets_spectrograms is not None else {}\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Denotes the number of batches per epoch.\n",
    "        \"\"\"\n",
    "        return len(self.df)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Generate one batch of data.\n",
    "        \"\"\"\n",
    "        X, y = self.__data_generation(index)\n",
    "        if self.augment:\n",
    "            X = self.__transform(X) \n",
    "        return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def log_and_Standarize(self,img):\n",
    "        # Log transform spectogram\n",
    "            img = np.clip(img, np.exp(-4), np.exp(8))\n",
    "            img = np.log(img)\n",
    "\n",
    "            # Standarize per image\n",
    "            ep = 1e-6\n",
    "            mu = np.nanmean(img.flatten())\n",
    "            std = np.nanstd(img.flatten())\n",
    "            img = (img - mu) / (std + ep)\n",
    "            img = np.nan_to_num(img, nan=0.0)\n",
    "            return img\n",
    "\n",
    "    def __data_generation(self, index):\n",
    "        \"\"\"\n",
    "        Generates data containing batch_size samples.\n",
    "        \"\"\"\n",
    "        X = np.zeros((128, 256, 12), dtype='float32')\n",
    "        y = np.zeros(6, dtype='float32')\n",
    "        img = np.ones((128,256), dtype='float32')\n",
    "        row = self.df.iloc[index]\n",
    "        if self.mode=='test': \n",
    "            r = 0\n",
    "        else: \n",
    "            r = int((row['min'] + row['max']) // 4)\n",
    "            \n",
    "        for region in range(4):\n",
    "            spectrogram_id_int = int(row.spectrogram_id)  # numpy.int64 → Python int\n",
    "            img = self.spectrograms[spectrogram_id_int][r:r+300, region*100:(region+1)*100].T\n",
    "            img = self.log_and_Standarize(img)\n",
    "            X[14:-14, :, region] = img[:, 22:-22] / 2.0\n",
    "            \n",
    "#         img = self.eeg_spectrograms[row.eeg_id]\n",
    "#         img = img.to_numpy()\n",
    "#         img = self.log_and_Standarize(img)\n",
    "#         img = resize(img, (128, 256, 4))\n",
    "#         X[:, :, 4:8] = img\n",
    "\n",
    "        # Combine wavelet features\n",
    "        img = self.wavelets_spectrograms[row.spectrogram_id]\n",
    "        img = self.log_and_Standarize(img)\n",
    "        img = resize(img, (128, 256,4))\n",
    "        X[:, :, 4:8] = img\n",
    "\n",
    "\n",
    "        if self.mode != 'test':\n",
    "            y = row[label_cols].values.astype(np.float32)\n",
    "    \n",
    "        return X, y\n",
    "    \n",
    "    def __transform(self, img):\n",
    "        transforms = A.Compose([\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "        ])\n",
    "        return transforms(image=img)['image']\n",
    "\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, config, num_classes: int = 6, pretrained: bool = False):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.USE_KAGGLE_SPECTROGRAMS = True\n",
    "        self.USE_EEG_SPECTROGRAMS = True\n",
    "        self.USE_WAVELET_SPECTROGRAMS = True\n",
    "        self.model = timm.create_model(\n",
    "            config.MODEL,\n",
    "            pretrained=pretrained,\n",
    "            drop_rate = 0.1,\n",
    "            drop_path_rate = 0.2,\n",
    "        )\n",
    "        if config.FREEZE:\n",
    "            for i,(name, param) in enumerate(list(self.model.named_parameters())\\\n",
    "                                             [0:config.NUM_FROZEN_LAYERS]):\n",
    "                param.requires_grad = False\n",
    "\n",
    "        self.features = nn.Sequential(*list(self.model.children())[:-2])\n",
    "        self.custom_layers = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.model.num_features, num_classes)\n",
    "        )\n",
    "\n",
    "    def __reshape_input(self, x):\n",
    "        \"\"\"\n",
    "        Reshapes input torch.Size([8, 128, 256, 12]) -> [8, 3, 512, 768] monotone image.\n",
    "        \"\"\" \n",
    "        components = []\n",
    "        if self.USE_KAGGLE_SPECTROGRAMS:\n",
    "            spectograms = [x[:, :, :, i:i+1] for i in range(4)]\n",
    "            components.append(torch.cat(spectograms, dim=1))\n",
    "        if self.USE_EEG_SPECTROGRAMS:\n",
    "            eegs = [x[:, :, :, i:i+1] for i in range(4,8)]\n",
    "            eegs = torch.cat(eegs, dim=1)\n",
    "            components.append(eegs)\n",
    "\n",
    "        if self.USE_WAVELET_SPECTROGRAMS:\n",
    "            wavelets = [x[:, :, :, i:i+1] for i in range(8,12)]\n",
    "            wavelets = torch.cat(wavelets, dim=1)\n",
    "            components.append(wavelets)\n",
    "\n",
    "        if components:\n",
    "            x = torch.cat(components, dim=2)\n",
    "\n",
    "        x = torch.cat([x, x, x], dim=3)  \n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.__reshape_input(x)\n",
    "        x = self.features(x)\n",
    "        x = self.custom_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64fd690e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T21:00:22.671839Z",
     "iopub.status.busy": "2024-04-08T21:00:22.671465Z",
     "iopub.status.idle": "2024-04-08T21:00:22.682150Z",
     "shell.execute_reply": "2024-04-08T21:00:22.681045Z"
    },
    "papermill": {
     "duration": 0.019083,
     "end_time": "2024-04-08T21:00:22.684586",
     "exception": false,
     "start_time": "2024-04-08T21:00:22.665503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@log_time\n",
    "def train_epoch(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    \"\"\"One epoch training pass.\"\"\"\n",
    "    model.train() \n",
    "    criterion = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=config.AMP)\n",
    "    losses = AverageMeter()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    \n",
    "    # ========== ITERATE OVER TRAIN BATCHES ============\n",
    "    with tqdm(train_loader, unit=\"train_batch\", desc='Train') as tqdm_train_loader:\n",
    "        for step, (X, y) in enumerate(tqdm_train_loader):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            batch_size = y.size(0)\n",
    "            with torch.cuda.amp.autocast(enabled=config.AMP):\n",
    "                y_preds = model(X) \n",
    "                loss = criterion(F.log_softmax(y_preds, dim=1), y)\n",
    "            if config.GRADIENT_ACCUMULATION_STEPS > 1:\n",
    "                loss = loss / config.GRADIENT_ACCUMULATION_STEPS\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            scaler.scale(loss).backward()\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config.MAX_GRAD_NORM)\n",
    "\n",
    "            if (step + 1) % config.GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                global_step += 1\n",
    "                scheduler.step()\n",
    "            end = time.time()\n",
    "\n",
    "            # ========== LOG INFO ==========\n",
    "            if step % config.PRINT_FREQ == 0 or step == (len(train_loader)-1):\n",
    "                print('Epoch: [{0}][{1}/{2}] '\n",
    "                      'Elapsed {remain:s} '\n",
    "                      'Loss: {loss.avg:.4f} '\n",
    "                      'Grad: {grad_norm:.4f}  '\n",
    "                      'LR: {lr:.8f}  '\n",
    "                      .format(epoch+1, step, len(train_loader), \n",
    "                              remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                              loss=losses,\n",
    "                              grad_norm=grad_norm,\n",
    "                              lr=scheduler.get_last_lr()[0]))\n",
    "\n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83114fec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T21:00:22.698132Z",
     "iopub.status.busy": "2024-04-08T21:00:22.696875Z",
     "iopub.status.idle": "2024-04-08T21:00:22.707341Z",
     "shell.execute_reply": "2024-04-08T21:00:22.706219Z"
    },
    "papermill": {
     "duration": 0.019097,
     "end_time": "2024-04-08T21:00:22.709869",
     "exception": false,
     "start_time": "2024-04-08T21:00:22.690772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@log_time\n",
    "def valid_epoch(valid_loader, model, criterion, device):\n",
    "    model.eval()\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    losses = AverageMeter()\n",
    "    prediction_dict = {}\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "    with tqdm(valid_loader, unit=\"valid_batch\", desc='Validation') as tqdm_valid_loader:\n",
    "        for step, (X, y) in enumerate(tqdm_valid_loader):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            batch_size = y.size(0)\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(X)\n",
    "                loss = criterion(F.log_softmax(y_preds, dim=1), y)\n",
    "            if config.GRADIENT_ACCUMULATION_STEPS > 1:\n",
    "                loss = loss / config.GRADIENT_ACCUMULATION_STEPS\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            y_preds = softmax(y_preds)\n",
    "            preds.append(y_preds.to('cpu').numpy())\n",
    "            end = time.time()\n",
    "\n",
    "            # ========== LOG INFO ==========\n",
    "            if step % config.PRINT_FREQ == 0 or step == (len(valid_loader)-1):\n",
    "                print('EVAL: [{0}/{1}] '\n",
    "                      'Elapsed {remain:s} '\n",
    "                      'Loss: {loss.avg:.4f} '\n",
    "                      .format(step, len(valid_loader),\n",
    "                              remain=timeSince(start, float(step+1)/len(valid_loader)),\n",
    "                              loss=losses))\n",
    "                \n",
    "    prediction_dict[\"predictions\"] = np.concatenate(preds)\n",
    "    return losses.avg, prediction_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e83c283",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T21:00:22.720867Z",
     "iopub.status.busy": "2024-04-08T21:00:22.720286Z",
     "iopub.status.idle": "2024-04-08T21:00:22.726001Z",
     "shell.execute_reply": "2024-04-08T21:00:22.724957Z"
    },
    "papermill": {
     "duration": 0.013309,
     "end_time": "2024-04-08T21:00:22.727874",
     "exception": false,
     "start_time": "2024-04-08T21:00:22.714565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "@log_time\n",
    "def get_result(oof_df):\n",
    "    kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "    labels = torch.tensor(oof_df[label_cols].values)\n",
    "    preds = torch.tensor(oof_df[target_preds].values)\n",
    "    preds = F.log_softmax(preds, dim=1)\n",
    "    result = kl_loss(preds, labels)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8acd3e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T21:00:22.739990Z",
     "iopub.status.busy": "2024-04-08T21:00:22.739378Z",
     "iopub.status.idle": "2024-04-08T21:00:22.744646Z",
     "shell.execute_reply": "2024-04-08T21:00:22.743761Z"
    },
    "papermill": {
     "duration": 0.01422,
     "end_time": "2024-04-08T21:00:22.746883",
     "exception": false,
     "start_time": "2024-04-08T21:00:22.732663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_wavelet_features(signal, wavelet='db4', level=5):\n",
    "    coeffs = pywt.wavedec(signal, wavelet, level=level)\n",
    "    # 从小波系数中提取特征而不是直接用小波系数，因为有不规则大小。\n",
    "    features = []\n",
    "    for coeff in coeffs:\n",
    "        features.extend([np.mean(coeff), np.std(coeff)])\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41c72883",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T21:00:22.758362Z",
     "iopub.status.busy": "2024-04-08T21:00:22.757770Z",
     "iopub.status.idle": "2024-04-08T21:00:22.768262Z",
     "shell.execute_reply": "2024-04-08T21:00:22.767198Z"
    },
    "papermill": {
     "duration": 0.019012,
     "end_time": "2024-04-08T21:00:22.770700",
     "exception": false,
     "start_time": "2024-04-08T21:00:22.751688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@log_time\n",
    "def loading_parquet(train_df, config = config, READ_SPEC_FILES = True,READ_EEG_SPEC_FILES = True,wavelet = 'None'):\n",
    "    # paths_spectograms = glob(paths.TRAIN_SPECTOGRAMS + \"*.parquet\")\n",
    "    paths_spectrograms = glob(str(paths.TEST_SPECTROGRAMS / \"*.parquet\"))\n",
    "    print(f'There are {len(paths_spectrograms)} spectrogram parquets in total path')\n",
    "\n",
    "        \n",
    "    all_spectrograms = {}\n",
    "    all_wavelet_spectrograms = {}\n",
    "    spectogram_ids = train_df['spectrogram_id'].unique()\n",
    "    print(f'There are {len(spectogram_ids)} spectrogram parquets in this training process')\n",
    "    for spec_id in tqdm(spectogram_ids):\n",
    "    # for file_path in tqdm(paths_spectograms):\n",
    "        file_path = f\"{paths.TEST_SPECTROGRAMS}/{spec_id}.parquet\"\n",
    "        aux = pd.read_parquet(file_path)\n",
    "        spec_arr = aux.fillna(0).values[:, 1:].T.astype(\"float32\")  # (Hz, Time) = (400, 300)\n",
    "        wavelet_features = np.array([compute_wavelet_features(row, wavelet=wavelet) for row in spec_arr])\n",
    "        name = int(file_path.split(\"/\")[-1].split('.')[0])\n",
    "        # all_spectrograms[name] = aux.iloc[:,1:].values  \n",
    "        all_spectrograms[name] = aux.fillna(0).iloc[:,1:].values.astype(\"float32\")\n",
    "        all_wavelet_spectrograms[name] = wavelet_features\n",
    "        del aux\n",
    "        del wavelet_features\n",
    "\n",
    "        \n",
    "    if config.VISUALIZE:\n",
    "        idx = np.random.randint(0,len(paths_spectrograms))\n",
    "        spectrogram_path = paths_spectrograms[idx]\n",
    "        plot_spectrogram(spectrogram_path)\n",
    "\n",
    "    # Read EEG Spectrograms\n",
    "    # paths_eegs = glob(paths.TRAIN_EEGS + \"*.parquet\")\n",
    "    paths_eegs = glob(str(paths.TEST_EEGS / \"*.parquet\"))\n",
    "    print(f'There are {len(paths_eegs)} EEG spectrograms in total path')\n",
    "    all_eegs = {}\n",
    "    eeg_ids = train_df['eeg_id'].unique()\n",
    "    print(f'There are {len(eeg_ids)} EEG spectrograms in this training path')\n",
    "    for eeg_id in tqdm(eeg_ids):\n",
    "        file_path = f\"{paths.TEST_EEGS}/{eeg_id}.parquet\"\n",
    "        eeg_spectogram =  pd.read_parquet(file_path)\n",
    "        all_eegs[eeg_id] = eeg_spectogram\n",
    "        del eeg_spectogram\n",
    "\n",
    "    return all_spectrograms,all_eegs,all_wavelet_spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b08978a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T21:00:22.782324Z",
     "iopub.status.busy": "2024-04-08T21:00:22.781935Z",
     "iopub.status.idle": "2024-04-08T21:00:22.789288Z",
     "shell.execute_reply": "2024-04-08T21:00:22.788140Z"
    },
    "papermill": {
     "duration": 0.015954,
     "end_time": "2024-04-08T21:00:22.791591",
     "exception": false,
     "start_time": "2024-04-08T21:00:22.775637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference_function(test_loader, model, device):\n",
    "    model.eval()\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    prediction_dict = {}\n",
    "    preds = []\n",
    "    with tqdm(test_loader, unit=\"test_batch\", desc='Inference') as tqdm_test_loader:\n",
    "        for step, (X, y) in enumerate(tqdm_test_loader):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            batch_size = y.size(0)\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(X)\n",
    "            y_preds = softmax(y_preds)\n",
    "            preds.append(y_preds.to('cpu').numpy()) \n",
    "                \n",
    "    prediction_dict[\"predictions\"] = np.concatenate(preds) \n",
    "    return prediction_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbb1ba37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T21:00:22.802658Z",
     "iopub.status.busy": "2024-04-08T21:00:22.802257Z",
     "iopub.status.idle": "2024-04-08T21:00:22.809784Z",
     "shell.execute_reply": "2024-04-08T21:00:22.808838Z"
    },
    "papermill": {
     "duration": 0.015674,
     "end_time": "2024-04-08T21:00:22.811974",
     "exception": false,
     "start_time": "2024-04-08T21:00:22.796300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def maddest(d, axis: int = None):\n",
    "    \"\"\"\n",
    "    Denoise function.\n",
    "    \"\"\"\n",
    "    return np.mean(np.absolute(d - np.mean(d, axis)), axis)\n",
    "\n",
    "def denoise(x: np.ndarray, wavelet: str = 'haar', level: int = 1): \n",
    "    coeff = pywt.wavedec(x, wavelet, mode=\"per\") # multilevel 1D Discrete Wavelet Transform of data.\n",
    "    sigma = (1/0.6745) * maddest(coeff[-level])\n",
    "    uthresh = sigma * np.sqrt(2*np.log(len(x)))\n",
    "    coeff[1:] = (pywt.threshold(i, value=uthresh, mode='hard') for i in coeff[1:])\n",
    "    output = pywt.waverec(coeff, wavelet, mode='per')\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a96f35d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T21:00:22.823153Z",
     "iopub.status.busy": "2024-04-08T21:00:22.822482Z",
     "iopub.status.idle": "2024-04-08T21:00:29.221993Z",
     "shell.execute_reply": "2024-04-08T21:00:29.220459Z"
    },
    "papermill": {
     "duration": 6.408061,
     "end_time": "2024-04-08T21:00:29.224686",
     "exception": false,
     "start_time": "2024-04-08T21:00:22.816625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log file path: /kaggle/working/new_version_inference_record.log\n",
      "seed_everything took 0.0025 seconds.\n",
      "   spectrogram_id      eeg_id  patient_id\n",
      "0          853520  3911565283        6885\n",
      "There are 1 spectrogram parquets in total path\n",
      "There are 1 spectrogram parquets in this training process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 EEG spectrograms in total path\n",
      "There are 1 EEG spectrograms in this training path\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 22.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading_parquet took 0.3769 seconds.\n",
      "all_spectrograms: {853520: array([[14.91, 17.11, 11.66, ...,  0.05,  0.04,  0.05],\n",
      "       [11.13, 10.95, 10.77, ...,  0.03,  0.03,  0.02],\n",
      "       [10.88, 10.57,  8.79, ...,  0.05,  0.06,  0.06],\n",
      "       ...,\n",
      "       [ 9.61, 13.32,  9.19, ...,  0.39,  0.56,  0.29],\n",
      "       [ 8.43, 11.84, 13.64, ...,  0.45,  0.45,  0.34],\n",
      "       [12.33, 11.84,  9.42, ...,  0.46,  0.54,  0.29]], dtype=float32)}\n",
      "type(key): <class 'int'>\n",
      "all_eegs: {3911565283:             Fp1         F3         C3         P3         F7     T3         T5  \\\n",
      "0      9.210000 -47.459999  15.100000   8.220000 -16.900000 -22.99 -25.820000   \n",
      "1     -3.590000 -30.290001  32.380001  10.800000 -68.980003 -21.60 -15.080000   \n",
      "2    -26.040001 -60.070000   2.370000 -10.150000 -34.689999 -31.40 -31.920000   \n",
      "3     -3.040000 -36.250000  29.559999  14.530000 -14.010000 -11.90 -14.230000   \n",
      "4     -4.630000 -20.160000  25.190001   1.190000 -44.580002 -23.51 -30.709999   \n",
      "...         ...        ...        ...        ...        ...    ...        ...   \n",
      "9995 -26.889999 -45.480000 -17.250000 -23.570000  19.059999  -9.40 -27.120001   \n",
      "9996 -24.049999 -41.689999 -13.450000 -26.219999  14.210000   0.02 -30.030001   \n",
      "9997 -34.500000 -55.340000 -25.959999 -30.670000   8.890000  -9.74 -38.520000   \n",
      "9998 -16.110001 -35.980000  -8.570000 -12.020000  28.580000   5.45 -20.510000   \n",
      "9999  -3.260000 -17.840000   4.030000  -8.930000  34.270000   6.77 -15.670000   \n",
      "\n",
      "             O1         Fz         Cz         Pz         Fp2         F4  \\\n",
      "0    -10.090000  28.370001  -3.010000 -27.299999  101.040001  35.110001   \n",
      "1     -9.210000  26.360001  -8.980000 -32.279999   95.800003  26.389999   \n",
      "2    -26.980000  -1.940000 -28.770000 -49.770000   73.449997  -3.680000   \n",
      "3     -6.310000  26.040001  -2.770000 -25.030001   91.010002  22.610001   \n",
      "4    -17.600000  25.420000  -8.860000 -33.959999   89.449997  19.440001   \n",
      "...         ...        ...        ...        ...         ...        ...   \n",
      "9995 -21.580000 -75.760002 -65.800003 -88.790001  -30.090000 -49.830002   \n",
      "9996 -22.219999 -75.440002 -68.639999 -91.099998  -33.180000 -45.610001   \n",
      "9997 -30.330000 -87.080002 -70.690002 -92.320000  -37.349998 -57.290001   \n",
      "9998 -10.300000 -65.459999 -50.730000 -71.650002  -15.970000 -36.380001   \n",
      "9999  -4.760000 -52.930000 -49.180000 -72.570000  -10.600000 -27.830000   \n",
      "\n",
      "             C4         P4         F8         T4         T6     O2         EKG  \n",
      "0     14.540000  18.330000  28.540001  44.090000  69.650002  30.74  171.679993  \n",
      "1      4.820000  10.540000  20.559999  32.060001  59.439999  23.32  178.279999  \n",
      "2    -17.320000 -16.150000  -8.270000   5.330000  45.180000   9.49  306.739990  \n",
      "3      6.900000   9.930000  15.480000  33.580002  69.620003  31.01  223.259995  \n",
      "4     -2.080000   6.110000   8.380000  24.180000  55.869999  19.91  170.759995  \n",
      "...         ...        ...        ...        ...        ...    ...         ...  \n",
      "9995 -75.339996 -61.139999 -71.889999 -53.299999  -8.130000 -12.38  -34.799999  \n",
      "9996 -78.809998 -61.259998 -71.889999 -55.009998 -12.320000 -15.15  -27.799999  \n",
      "9997 -80.209999 -67.320000 -72.919998 -57.110001 -12.330000 -15.20   21.980000  \n",
      "9998 -59.660000 -46.310001 -51.520000 -39.740002   6.770000   3.74   -5.800000  \n",
      "9999 -60.209999 -41.820000 -53.939999 -42.650002  -0.270000  -1.19  -54.950001  \n",
      "\n",
      "[10000 rows x 20 columns]}\n",
      "all_wavelet_spectrograms: {853520: array([[ 9.3701370e+01,  1.9662539e+01,  6.1223059e+00, ...,\n",
      "         9.9889193e+00,  4.8083369e-02,  9.8177519e+00],\n",
      "       [ 1.0632428e+02,  2.0712198e+01,  6.0130601e+00, ...,\n",
      "         1.0630186e+01, -7.6697387e-02,  1.0383412e+01],\n",
      "       [ 1.0189992e+02,  2.0185411e+01,  5.1330638e+00, ...,\n",
      "         1.0530858e+01, -6.7316622e-02,  9.6551704e+00],\n",
      "       ...,\n",
      "       [ 5.7240283e-01,  5.0416625e-01, -1.2374373e-02, ...,\n",
      "         3.8350087e-02, -1.8384766e-03,  3.5500515e-02],\n",
      "       [ 5.8442366e-01,  5.1768965e-01, -1.7677688e-03, ...,\n",
      "         4.8134070e-02, -3.7240959e-03,  3.5746299e-02],\n",
      "       [ 5.3616369e-01,  3.8144216e-01, -2.6516474e-03, ...,\n",
      "         5.0366923e-02, -1.1313711e-03,  3.2517485e-02]], dtype=float32)}\n",
      "X shape: torch.Size([128, 256, 12])\n",
      "y shape: torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  1.48test_batch/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  2.60test_batch/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  2.76test_batch/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  2.58test_batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submissionn shape: (1, 7)\n",
      "       eeg_id  seizure_vote  lpd_vote  gpd_vote  lrda_vote  grda_vote  \\\n",
      "0  3911565283       0.17056  0.061165  0.132191   0.059564   0.131449   \n",
      "\n",
      "   other_vote  \n",
      "0    0.445072  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    overall_start_time = time.time()\n",
    "    print(f\"Log file path: {log_filename.absolute()}\")\n",
    "    logging.info('--------------------------------------------------')\n",
    "    logging.info(f'Into loading stage')\n",
    "\n",
    "    target_preds = [x + \"_pred\" for x in ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']]\n",
    "    label_to_num = {'Seizure': 0, 'LPD': 1, 'GPD': 2, 'LRDA': 3, 'GRDA': 4, 'Other':5}\n",
    "    num_to_label = {v: k for k, v in label_to_num.items()}\n",
    "    seed_everything(config.SEED)\n",
    "\n",
    "    test_df = pd.read_csv(paths.TEST_CSV)\n",
    "    label_cols = test_df.columns[-6:]\n",
    "    print(test_df.head())\n",
    "\n",
    "    logging.info(f'Into loading stage: combine wavelet feature into X')\n",
    "    all_spectrograms,all_eegs,all_wavelet_spectrograms = loading_parquet(test_df, config = config, READ_SPEC_FILES = True,READ_EEG_SPEC_FILES = True,wavelet='db1')\n",
    "    print('all_spectrograms:',all_spectrograms)\n",
    "    for key in list(all_spectrograms.keys())[:5]:  # 打印前5个键的类型\n",
    "        print('type(key):',type(key))\n",
    "\n",
    "    print('all_eegs:',all_eegs)\n",
    "    print('all_wavelet_spectrograms:',all_wavelet_spectrograms)\n",
    "    test_dataset = CustomDataset(test_df, config, mode=\"test\",specs=all_spectrograms, eeg_specs=all_eegs,wavelets_spectrograms = all_wavelet_spectrograms)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=False\n",
    "    )\n",
    "    X, y = test_dataset[0]\n",
    "    print(f\"X shape: {X.shape}\")\n",
    "    print(f\"y shape: {y.shape}\")\n",
    "    \n",
    "\n",
    "    model_weights = [x for x in glob(str(paths.OUTPUT_DIR/\"*.pth\"))]\n",
    "\n",
    "    # model_weights = [x for x in glob(\"/kaggle/input/hms-efficientnetb0-5-folds/*.pth\")]\n",
    "    predictions = list()\n",
    "    for model_weight in model_weights:\n",
    "        test_dataset = CustomDataset(test_df, config, mode=\"test\", augment=False,specs=all_spectrograms, eeg_specs=all_eegs,wavelets_spectrograms = all_wavelet_spectrograms)\n",
    "        train_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=config.BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "            num_workers=config.NUM_WORKERS,\n",
    "            pin_memory=True, drop_last=False\n",
    "        )\n",
    "        model = CustomModel(config)\n",
    "        checkpoint = torch.load(model_weight,map_location=torch.device('cpu'))\n",
    "        model.load_state_dict(checkpoint[\"model\"])\n",
    "        model.to(device)\n",
    "        prediction_dict = inference_function(test_loader, model, device)\n",
    "        predictions.append(prediction_dict[\"predictions\"])\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "    predictions = np.array(predictions)\n",
    "    predictions = np.mean(predictions, axis=0)\n",
    "\n",
    "    TARGETS = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n",
    "    sub = pd.DataFrame({'eeg_id': test_df.eeg_id.values})\n",
    "    sub[TARGETS] = predictions\n",
    "    sub.to_csv('submission.csv',index=False)\n",
    "    print(f'Submissionn shape: {sub.shape}')\n",
    "    print(sub.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69e20ee",
   "metadata": {
    "papermill": {
     "duration": 0.006474,
     "end_time": "2024-04-08T21:00:29.238277",
     "exception": false,
     "start_time": "2024-04-08T21:00:29.231803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7469972,
     "sourceId": 59093,
     "sourceType": "competition"
    },
    {
     "datasetId": 4759669,
     "sourceId": 8067308,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 24.164645,
   "end_time": "2024-04-08T21:00:31.669933",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-08T21:00:07.505288",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
