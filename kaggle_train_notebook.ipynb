{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a69b4708",
   "metadata": {
    "_cell_guid": "3d3a4cad-11da-44b0-99da-e5ac5233222d",
    "_uuid": "f61d9f2f-5eec-496f-bed8-683ad897c39b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-04-08T17:24:33.425264Z",
     "iopub.status.busy": "2024-04-08T17:24:33.424512Z",
     "iopub.status.idle": "2024-04-08T17:24:43.700430Z",
     "shell.execute_reply": "2024-04-08T17:24:43.699433Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 10.287478,
     "end_time": "2024-04-08T17:24:43.702842",
     "exception": false,
     "start_time": "2024-04-08T17:24:33.415364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from glob import glob\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, List\n",
    "\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "from skimage.transform import resize\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "import torch.nn.functional as F\n",
    "import logging\n",
    "import functools\n",
    "import pywt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46bc183c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T17:24:43.718861Z",
     "iopub.status.busy": "2024-04-08T17:24:43.717954Z",
     "iopub.status.idle": "2024-04-08T17:24:43.805186Z",
     "shell.execute_reply": "2024-04-08T17:24:43.804116Z"
    },
    "papermill": {
     "duration": 0.097237,
     "end_time": "2024-04-08T17:24:43.807348",
     "exception": false,
     "start_time": "2024-04-08T17:24:43.710111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 GPU(s)\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Using', torch.cuda.device_count(), 'GPU(s)')\n",
    "\n",
    "\n",
    "\n",
    "class config:\n",
    "    AMP = True\n",
    "    BATCH_SIZE_TRAIN = 32\n",
    "    BATCH_SIZE_VALID = 32\n",
    "    EPOCHS = 3\n",
    "    FOLDS = 5\n",
    "    FREEZE = False\n",
    "    GRADIENT_ACCUMULATION_STEPS = 1\n",
    "    MAX_GRAD_NORM = 1e7\n",
    "    MODEL = \"efficientnet_b2\"\n",
    "    NUM_FROZEN_LAYERS = 39\n",
    "    NUM_WORKERS = 0 # multiprocessing.cpu_count()\n",
    "    PRINT_FREQ = 20\n",
    "    SEED = 20\n",
    "    TRAIN_FULL_DATA = True\n",
    "    VISUALIZE = False\n",
    "    WEIGHT_DECAY = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20b97c69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T17:24:43.822967Z",
     "iopub.status.busy": "2024-04-08T17:24:43.822659Z",
     "iopub.status.idle": "2024-04-08T17:24:43.828537Z",
     "shell.execute_reply": "2024-04-08T17:24:43.827724Z"
    },
    "papermill": {
     "duration": 0.015943,
     "end_time": "2024-04-08T17:24:43.830374",
     "exception": false,
     "start_time": "2024-04-08T17:24:43.814431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class paths:\n",
    "    # OUTPUT_DIR = \"/kaggle/working/\"\n",
    "    # PRE_LOADED_EEGS = '/kaggle/input/brain-eeg-spectrograms/eeg_specs.npy'\n",
    "    # PRE_LOADED_SPECTOGRAMS = '/kaggle/input/brain-spectrograms/specs.npy'\n",
    "    # TRAIN_CSV = \"/kaggle/input/hms-harmful-brain-activity-classification/train.csv\"\n",
    "    # TRAIN_EEGS = \"/kaggle/input/brain-eeg-spectrograms/EEG_Spectrograms/\"\n",
    "    # TRAIN_SPECTOGRAMS = \"/kaggle/input/hms-harmful-brain-activity-classification/train_spectrograms/\"\n",
    "    ROOT = Path.cwd()\n",
    "    INPUT = ROOT / \"input\"\n",
    "    OUTPUT_DIR = \"/kaggle/working/output\"\n",
    "#     DATA = Path(\"./original_data\")\n",
    "    DATA = Path(\"/kaggle/input/hms-harmful-brain-activity-classification\")\n",
    "    Pre_load_path = Path('/kaggle/input/single-spec-wavelets')\n",
    "    PRE_LOADED_EEGS = Pre_load_path/'./Kaggle/Input/brain-eeg-spectrograms/eeg_specs.npy'\n",
    "    PRE_LOADED_SPECTROGRAMS = Pre_load_path/'./Kaggle/Input/brain-spectrograms/specs.npy'\n",
    "    PRE_LOADED_Wavelets = Pre_load_path/ './Kaggle/Input/brain-wavelets/specs.npy'\n",
    "    \n",
    "    \n",
    "    TRAIN_SPECTROGRAMS = DATA / \"train_spectrograms\"\n",
    "    TRAIN_EEGS = DATA / \"train_eegs\"\n",
    "    TRAIN_CSV = DATA / \"train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7570410a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T17:24:43.845197Z",
     "iopub.status.busy": "2024-04-08T17:24:43.844890Z",
     "iopub.status.idle": "2024-04-08T17:24:43.849014Z",
     "shell.execute_reply": "2024-04-08T17:24:43.848317Z"
    },
    "papermill": {
     "duration": 0.013602,
     "end_time": "2024-04-08T17:24:43.850890",
     "exception": false,
     "start_time": "2024-04-08T17:24:43.837288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(paths.OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4d73c8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T17:24:43.866235Z",
     "iopub.status.busy": "2024-04-08T17:24:43.865715Z",
     "iopub.status.idle": "2024-04-08T17:24:43.871776Z",
     "shell.execute_reply": "2024-04-08T17:24:43.870946Z"
    },
    "papermill": {
     "duration": 0.015779,
     "end_time": "2024-04-08T17:24:43.873605",
     "exception": false,
     "start_time": "2024-04-08T17:24:43.857826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_filename = Path('/kaggle/working/new_version_training_record.log')\n",
    "\n",
    "logging.basicConfig(filename=log_filename, level=logging.INFO,\n",
    "                    format='%(asctime)s %(levelname)s %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "def log_time(func):\n",
    "    \"\"\"warpper for logging running time\"\"\"\n",
    "\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        logging.info(f\"{func.__name__} took {end_time - start_time:.4f} seconds.\")\n",
    "        print(f\"{func.__name__} took {end_time - start_time:.4f} seconds.\")\n",
    "        return result\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44855382",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T17:24:43.888696Z",
     "iopub.status.busy": "2024-04-08T17:24:43.888194Z",
     "iopub.status.idle": "2024-04-08T17:24:43.903866Z",
     "shell.execute_reply": "2024-04-08T17:24:43.903220Z"
    },
    "papermill": {
     "duration": 0.025255,
     "end_time": "2024-04-08T17:24:43.905723",
     "exception": false,
     "start_time": "2024-04-08T17:24:43.880468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s: float):\n",
    "    \"Convert to minutes.\"\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since: float, percent: float):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "\n",
    "def plot_spectrogram(spectrogram_path: str):\n",
    "    \"\"\"\n",
    "    Source: https://www.kaggle.com/code/mvvppp/hms-eda-and-domain-journey\n",
    "    Visualize spectogram recordings from a parquet file.\n",
    "    :param spectrogram_path: path to the spectogram parquet.\n",
    "    \"\"\"\n",
    "    sample_spect = pd.read_parquet(spectrogram_path)\n",
    "    \n",
    "    split_spect = {\n",
    "        \"LL\": sample_spect.filter(regex='^LL', axis=1),\n",
    "        \"RL\": sample_spect.filter(regex='^RL', axis=1),\n",
    "        \"RP\": sample_spect.filter(regex='^RP', axis=1),\n",
    "        \"LP\": sample_spect.filter(regex='^LP', axis=1),\n",
    "    }\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 12))\n",
    "    axes = axes.flatten()\n",
    "    label_interval = 5\n",
    "    for i, split_name in enumerate(split_spect.keys()):\n",
    "        ax = axes[i]\n",
    "        img = ax.imshow(np.log(split_spect[split_name]).T, cmap='viridis', aspect='auto', origin='lower')\n",
    "        cbar = fig.colorbar(img, ax=ax)\n",
    "        cbar.set_label('Log(Value)')\n",
    "        ax.set_title(split_name)\n",
    "        ax.set_ylabel(\"Frequency (Hz)\")\n",
    "        ax.set_xlabel(\"Time\")\n",
    "\n",
    "        ax.set_yticks(np.arange(len(split_spect[split_name].columns)))\n",
    "        ax.set_yticklabels([column_name[3:] for column_name in split_spect[split_name].columns])\n",
    "        frequencies = [column_name[3:] for column_name in split_spect[split_name].columns]\n",
    "        ax.set_yticks(np.arange(0, len(split_spect[split_name].columns), label_interval))\n",
    "        ax.set_yticklabels(frequencies[::label_interval])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "@log_time   \n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed) \n",
    "\n",
    "   \n",
    "def sep():\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "425b116a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T17:24:43.920887Z",
     "iopub.status.busy": "2024-04-08T17:24:43.920410Z",
     "iopub.status.idle": "2024-04-08T17:24:43.937760Z",
     "shell.execute_reply": "2024-04-08T17:24:43.936961Z"
    },
    "papermill": {
     "duration": 0.027047,
     "end_time": "2024-04-08T17:24:43.939710",
     "exception": false,
     "start_time": "2024-04-08T17:24:43.912663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, df: pd.DataFrame, config,\n",
    "        augment: bool = False, mode: str = 'train',\n",
    "        specs: Dict[int, np.ndarray] = None,\n",
    "        eeg_specs: Dict[int, np.ndarray] = None,\n",
    "        wavelets_spectrograms: Dict[int, np.ndarray] = None\n",
    "    ): \n",
    "        self.df = df\n",
    "        self.config = config\n",
    "        self.batch_size = self.config.BATCH_SIZE_TRAIN\n",
    "        self.augment = augment\n",
    "        self.mode = mode\n",
    "        self.spectrograms = specs if specs is not None else {}\n",
    "        self.eeg_spectrograms = eeg_specs if eeg_specs is not None else {}\n",
    "        self.wavelets_spectrograms = wavelets_spectrograms if wavelets_spectrograms is not None else {}\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Denotes the number of batches per epoch.\n",
    "        \"\"\"\n",
    "        return len(self.df)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Generate one batch of data.\n",
    "        \"\"\"\n",
    "        X, y = self.__data_generation(index)\n",
    "        if self.augment:\n",
    "            X = self.__transform(X) \n",
    "        return torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def log_and_Standarize(self,img):\n",
    "        # Log transform spectogram\n",
    "            img = np.clip(img, np.exp(-4), np.exp(8))\n",
    "            img = np.log(img)\n",
    "\n",
    "            # Standarize per image\n",
    "            ep = 1e-6\n",
    "            mu = np.nanmean(img.flatten())\n",
    "            std = np.nanstd(img.flatten())\n",
    "            img = (img - mu) / (std + ep)\n",
    "            img = np.nan_to_num(img, nan=0.0)\n",
    "            return img\n",
    "\n",
    "    def __data_generation(self, index):\n",
    "        \"\"\"\n",
    "        Generates data containing batch_size samples.\n",
    "        \"\"\"\n",
    "        X = np.zeros((128, 256, 8), dtype='float32')\n",
    "        y = np.zeros(6, dtype='float32')\n",
    "        img = np.ones((128,256), dtype='float32')\n",
    "        row = self.df.iloc[index]\n",
    "        if self.mode=='test': \n",
    "            r = 0\n",
    "        else: \n",
    "            r = int((row['min'] + row['max']) // 4)\n",
    "            \n",
    "        for region in range(4):\n",
    "            img = self.spectrograms[row.spectrogram_id][r:r+300, region*100:(region+1)*100].T\n",
    "            img = self.log_and_Standarize(img)\n",
    "            X[14:-14, :, region] = img[:, 22:-22] / 2.0\n",
    "            \n",
    "#         img = self.eeg_spectrograms[row.eeg_id]\n",
    "#         img = img.to_numpy()\n",
    "#         img = self.log_and_Standarize(img)\n",
    "#         img = resize(img, (128, 256, 4))\n",
    "#         X[:, :, 4:8] = img\n",
    "\n",
    "        # Combine wavelet features\n",
    "        img = self.wavelets_spectrograms[row.spectrogram_id]\n",
    "        img = self.log_and_Standarize(img)\n",
    "        img = resize(img, (128, 256,4))\n",
    "#         X[:, :, 8:12] = img\n",
    "        X[:, :, 4:8] = img\n",
    "\n",
    "\n",
    "        if self.mode != 'test':\n",
    "            y = row[label_cols].values.astype(np.float32)\n",
    "    \n",
    "        return X, y\n",
    "    \n",
    "    def __transform(self, img):\n",
    "        transforms = A.Compose([\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "        ])\n",
    "        return transforms(image=img)['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f52bf77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T17:24:43.956319Z",
     "iopub.status.busy": "2024-04-08T17:24:43.955606Z",
     "iopub.status.idle": "2024-04-08T17:24:43.967280Z",
     "shell.execute_reply": "2024-04-08T17:24:43.966603Z"
    },
    "papermill": {
     "duration": 0.022487,
     "end_time": "2024-04-08T17:24:43.969156",
     "exception": false,
     "start_time": "2024-04-08T17:24:43.946669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, config, num_classes: int = 6, pretrained: bool = True):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.USE_KAGGLE_SPECTROGRAMS = True\n",
    "        self.USE_EEG_SPECTROGRAMS = False\n",
    "        self.USE_WAVELET_SPECTROGRAMS = True\n",
    "        self.model = timm.create_model(\n",
    "            config.MODEL,\n",
    "            pretrained=pretrained,\n",
    "            drop_rate = 0.1,\n",
    "            drop_path_rate = 0.2,\n",
    "        )\n",
    "        if config.FREEZE:\n",
    "            for i,(name, param) in enumerate(list(self.model.named_parameters())\\\n",
    "                                             [0:config.NUM_FROZEN_LAYERS]):\n",
    "                param.requires_grad = False\n",
    "\n",
    "        self.features = nn.Sequential(*list(self.model.children())[:-2])\n",
    "        self.custom_layers = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.model.num_features, num_classes)\n",
    "        )\n",
    "\n",
    "    def __reshape_input(self, x):\n",
    "        \"\"\"\n",
    "        Reshapes input torch.Size([8, 128, 256, 12]) -> [8, 3, 512, 768] monotone image.\n",
    "        \"\"\" \n",
    "        components = []\n",
    "        if self.USE_KAGGLE_SPECTROGRAMS:\n",
    "            spectograms = [x[:, :, :, i:i+1] for i in range(4)]\n",
    "#             components.append(torch.cat(spectograms, dim=1))\n",
    "#         if self.USE_EEG_SPECTROGRAMS:\n",
    "#             eegs = [x[:, :, :, i:i+1] for i in range(4,8)]\n",
    "#             eegs = torch.cat(eegs, dim=1)\n",
    "#             components.append(eegs)\n",
    "\n",
    "        if self.USE_WAVELET_SPECTROGRAMS:\n",
    "#             wavelets = [x[:, :, :, i:i+1] for i in range(8,12)]\n",
    "            wavelets = [x[:, :, :, i:i+1] for i in range(4,8)]\n",
    "            wavelets = torch.cat(wavelets, dim=1)\n",
    "            components.append(wavelets)\n",
    "\n",
    "        if components:\n",
    "            x = torch.cat(components, dim=2)\n",
    "\n",
    "        x = torch.cat([x, x, x], dim=3)  \n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.__reshape_input(x)\n",
    "        x = self.features(x)\n",
    "        x = self.custom_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c89a020",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T17:24:43.984040Z",
     "iopub.status.busy": "2024-04-08T17:24:43.983779Z",
     "iopub.status.idle": "2024-04-08T17:24:43.994973Z",
     "shell.execute_reply": "2024-04-08T17:24:43.994206Z"
    },
    "papermill": {
     "duration": 0.020847,
     "end_time": "2024-04-08T17:24:43.996930",
     "exception": false,
     "start_time": "2024-04-08T17:24:43.976083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@log_time\n",
    "def train_epoch(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    \"\"\"One epoch training pass.\"\"\"\n",
    "    model.train() \n",
    "    criterion = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=config.AMP)\n",
    "    losses = AverageMeter()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    \n",
    "    # ========== ITERATE OVER TRAIN BATCHES ============\n",
    "    with tqdm(train_loader, unit=\"train_batch\", desc='Train') as tqdm_train_loader:\n",
    "        for step, (X, y) in enumerate(tqdm_train_loader):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            batch_size = y.size(0)\n",
    "            with torch.cuda.amp.autocast(enabled=config.AMP):\n",
    "                y_preds = model(X) \n",
    "                loss = criterion(F.log_softmax(y_preds, dim=1), y)\n",
    "            if config.GRADIENT_ACCUMULATION_STEPS > 1:\n",
    "                loss = loss / config.GRADIENT_ACCUMULATION_STEPS\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            scaler.scale(loss).backward()\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config.MAX_GRAD_NORM)\n",
    "\n",
    "            if (step + 1) % config.GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                global_step += 1\n",
    "                scheduler.step()\n",
    "            end = time.time()\n",
    "\n",
    "            # ========== LOG INFO ==========\n",
    "            if step % config.PRINT_FREQ == 0 or step == (len(train_loader)-1):\n",
    "                print('Epoch: [{0}][{1}/{2}] '\n",
    "                      'Elapsed {remain:s} '\n",
    "                      'Loss: {loss.avg:.4f} '\n",
    "                      'Grad: {grad_norm:.4f}  '\n",
    "                      'LR: {lr:.8f}  '\n",
    "                      .format(epoch+1, step, len(train_loader), \n",
    "                              remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                              loss=losses,\n",
    "                              grad_norm=grad_norm,\n",
    "                              lr=scheduler.get_last_lr()[0]))\n",
    "\n",
    "    return losses.avg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56dcd34b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T17:24:44.012551Z",
     "iopub.status.busy": "2024-04-08T17:24:44.011803Z",
     "iopub.status.idle": "2024-04-08T17:24:44.021345Z",
     "shell.execute_reply": "2024-04-08T17:24:44.020635Z"
    },
    "papermill": {
     "duration": 0.019099,
     "end_time": "2024-04-08T17:24:44.023224",
     "exception": false,
     "start_time": "2024-04-08T17:24:44.004125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@log_time\n",
    "def valid_epoch(valid_loader, model, criterion, device):\n",
    "    model.eval()\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    losses = AverageMeter()\n",
    "    prediction_dict = {}\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "    with tqdm(valid_loader, unit=\"valid_batch\", desc='Validation') as tqdm_valid_loader:\n",
    "        for step, (X, y) in enumerate(tqdm_valid_loader):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            batch_size = y.size(0)\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(X)\n",
    "                loss = criterion(F.log_softmax(y_preds, dim=1), y)\n",
    "            if config.GRADIENT_ACCUMULATION_STEPS > 1:\n",
    "                loss = loss / config.GRADIENT_ACCUMULATION_STEPS\n",
    "            losses.update(loss.item(), batch_size)\n",
    "            y_preds = softmax(y_preds)\n",
    "            preds.append(y_preds.to('cpu').numpy())\n",
    "            end = time.time()\n",
    "\n",
    "            # ========== LOG INFO ==========\n",
    "            if step % config.PRINT_FREQ == 0 or step == (len(valid_loader)-1):\n",
    "                print('EVAL: [{0}/{1}] '\n",
    "                      'Elapsed {remain:s} '\n",
    "                      'Loss: {loss.avg:.4f} '\n",
    "                      .format(step, len(valid_loader),\n",
    "                              remain=timeSince(start, float(step+1)/len(valid_loader)),\n",
    "                              loss=losses))\n",
    "                \n",
    "    prediction_dict[\"predictions\"] = np.concatenate(preds)\n",
    "    return losses.avg, prediction_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56f28ed0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T17:24:44.038289Z",
     "iopub.status.busy": "2024-04-08T17:24:44.038026Z",
     "iopub.status.idle": "2024-04-08T17:24:44.051335Z",
     "shell.execute_reply": "2024-04-08T17:24:44.050541Z"
    },
    "papermill": {
     "duration": 0.023137,
     "end_time": "2024-04-08T17:24:44.053238",
     "exception": false,
     "start_time": "2024-04-08T17:24:44.030101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@log_time\n",
    "def train_loop(df, fold):\n",
    "    \n",
    "    logging.info(f\"========== Fold: {fold} training ==========\")\n",
    "\n",
    "    # ======== SPLIT ==========\n",
    "    train_folds = df[df['fold'] != fold].reset_index(drop=True)\n",
    "    valid_folds = df[df['fold'] == fold].reset_index(drop=True)\n",
    "    \n",
    "    # ======== DATASETS ==========\n",
    "    train_dataset = CustomDataset(train_folds, config, mode=\"train\", augment=True, specs=all_spectrograms,wavelets_spectrograms = all_wavelet_spectrograms )\n",
    "    valid_dataset = CustomDataset(valid_folds, config, mode=\"train\", augment=False, specs=all_spectrograms,wavelets_spectrograms = all_wavelet_spectrograms)\n",
    "    \n",
    "    # ======== DATALOADERS ==========\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=config.BATCH_SIZE_TRAIN,\n",
    "                              shuffle=False,\n",
    "                              num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset,\n",
    "                              batch_size=config.BATCH_SIZE_VALID,\n",
    "                              shuffle=False,\n",
    "                              num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=False)\n",
    "    \n",
    "    # ======== MODEL ==========\n",
    "    model = CustomModel(config)\n",
    "    model.to(device)\n",
    "\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.1, weight_decay=config.WEIGHT_DECAY)\n",
    "    scheduler = OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=1e-3,\n",
    "        epochs=config.EPOCHS,\n",
    "        steps_per_epoch=len(train_loader),\n",
    "        pct_start=0.1,\n",
    "        anneal_strategy=\"cos\",\n",
    "        final_div_factor=100,\n",
    "    )\n",
    "\n",
    "    # ======= LOSS ==========\n",
    "    criterion = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "    os.makedirs(paths.OUTPUT_DIR, exist_ok=True)\n",
    "    best_loss = np.inf\n",
    "    # ====== ITERATE EPOCHS ========\n",
    "    for epoch in range(config.EPOCHS):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # ======= TRAIN ==========\n",
    "        avg_train_loss = train_epoch(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "\n",
    "        # ======= EVALUATION ==========\n",
    "        avg_val_loss, prediction_dict = valid_epoch(valid_loader, model, criterion, device)\n",
    "        predictions = prediction_dict[\"predictions\"]\n",
    "        \n",
    "        # ======= SCORING ==========\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        logging.info(f'Epoch {epoch+1} - avg_train_loss: {avg_train_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        \n",
    "        if avg_val_loss < best_loss:\n",
    "            best_loss = avg_val_loss\n",
    "            logging.info(f'Epoch {epoch+1} - Save Best Loss: {best_loss:.4f} Model')\n",
    "#             torch.save({'model': model.state_dict(),\n",
    "#                         'predictions': predictions},\n",
    "#                         Path(paths.OUTPUT_DIR) / f\"{config.MODEL.replace('/', '_')}_fold_{fold}_best.pth\")\n",
    "            output_dir = paths.OUTPUT_DIR\n",
    "            full_path = os.path.join(output_dir, f\"{config.MODEL.replace('/', '_')}_epoch_{epoch}.pth\")\n",
    "#      \n",
    "            torch.save({'model': model.state_dict()},full_path)\n",
    "    ## TypeError: unsupported operand type(s) for +: 'WindowsPath' and 'str'\n",
    "    # predictions = torch.load(paths.OUTPUT_DIR + f\"/{config.MODEL.replace('/', '_')}_fold_{fold}_best.pth\", \n",
    "    #                          map_location=torch.device('cpu'))['predictions']\n",
    "    predictions = torch.load(Path(paths.OUTPUT_DIR) / f\"{config.MODEL.replace('/', '_')}_fold_{fold}_best.pth\",\n",
    "                         map_location=torch.device('cpu'))['predictions']\n",
    "\n",
    "    valid_folds[target_preds] = predictions\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return valid_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1d700ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T17:24:44.068624Z",
     "iopub.status.busy": "2024-04-08T17:24:44.068123Z",
     "iopub.status.idle": "2024-04-08T17:24:44.073204Z",
     "shell.execute_reply": "2024-04-08T17:24:44.072228Z"
    },
    "papermill": {
     "duration": 0.014966,
     "end_time": "2024-04-08T17:24:44.075139",
     "exception": false,
     "start_time": "2024-04-08T17:24:44.060173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/output\n"
     ]
    }
   ],
   "source": [
    "print(paths.OUTPUT_DIR)\n",
    "output_dir = Path(paths.OUTPUT_DIR)\n",
    "output_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cd96322",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T17:24:44.090837Z",
     "iopub.status.busy": "2024-04-08T17:24:44.090564Z",
     "iopub.status.idle": "2024-04-08T17:24:44.099640Z",
     "shell.execute_reply": "2024-04-08T17:24:44.098822Z"
    },
    "papermill": {
     "duration": 0.018829,
     "end_time": "2024-04-08T17:24:44.101536",
     "exception": false,
     "start_time": "2024-04-08T17:24:44.082707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@log_time\n",
    "def train_loop_full_data(df):\n",
    "    train_dataset = CustomDataset(df, config, mode=\"train\", augment=True,specs=all_spectrograms,wavelets_spectrograms = all_wavelet_spectrograms)\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=config.BATCH_SIZE_TRAIN,\n",
    "                              shuffle=False,\n",
    "                              num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=True)\n",
    "    model = CustomModel(config)\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.1, weight_decay=config.WEIGHT_DECAY)\n",
    "    scheduler = OneCycleLR(\n",
    "        optimizer,\n",
    "        max_lr=1e-3,\n",
    "        epochs=config.EPOCHS,\n",
    "        steps_per_epoch=len(train_loader),\n",
    "        pct_start=0.1,\n",
    "        anneal_strategy=\"cos\",\n",
    "        final_div_factor=100,\n",
    "    )\n",
    "    criterion = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "    best_loss = np.inf\n",
    "    for epoch in range(config.EPOCHS):\n",
    "        start_time = time.time()\n",
    "        avg_train_loss = train_epoch(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "        elapsed = time.time() - start_time\n",
    "        logging.info(f'Epoch {epoch+1} - avg_train_loss: {avg_train_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        output_dir = paths.OUTPUT_DIR\n",
    "        full_path = os.path.join(output_dir, f\"{config.MODEL.replace('/', '_')}_epoch_{epoch}.pth\")\n",
    "#         filepath = paths.OUTPUT_DIR + f\"/{config.MODEL.replace('/', '_')}_epoch_{epoch}.pth\"\n",
    "        torch.save(\n",
    "            {'model': model.state_dict()},\n",
    "            full_path)\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd98ffea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T17:24:44.116985Z",
     "iopub.status.busy": "2024-04-08T17:24:44.116437Z",
     "iopub.status.idle": "2024-04-08T17:24:44.120259Z",
     "shell.execute_reply": "2024-04-08T17:24:44.119384Z"
    },
    "papermill": {
     "duration": 0.013658,
     "end_time": "2024-04-08T17:24:44.122207",
     "exception": false,
     "start_time": "2024-04-08T17:24:44.108549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = CustomModel(config) \n",
    "# epoch = 5\n",
    "# output_dir = paths.OUTPUT_DIR\n",
    "# full_path = os.path.join(output_dir, f\"{config.MODEL.replace('/', '_')}_epoch_{epoch}.pth\")\n",
    "# print(full_path)\n",
    "# torch.save(\n",
    "#             {'model': model.state_dict()},\n",
    "#             full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d01171d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T17:24:44.137125Z",
     "iopub.status.busy": "2024-04-08T17:24:44.136845Z",
     "iopub.status.idle": "2024-04-08T17:24:44.141788Z",
     "shell.execute_reply": "2024-04-08T17:24:44.140941Z"
    },
    "papermill": {
     "duration": 0.014639,
     "end_time": "2024-04-08T17:24:44.143783",
     "exception": false,
     "start_time": "2024-04-08T17:24:44.129144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@log_time\n",
    "def get_result(oof_df):\n",
    "    kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "    labels = torch.tensor(oof_df[label_cols].values)\n",
    "    preds = torch.tensor(oof_df[target_preds].values)\n",
    "    preds = F.log_softmax(preds, dim=1)\n",
    "    result = kl_loss(preds, labels)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f154a3bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T17:24:44.158758Z",
     "iopub.status.busy": "2024-04-08T17:24:44.158489Z",
     "iopub.status.idle": "2024-04-08T17:24:44.165940Z",
     "shell.execute_reply": "2024-04-08T17:24:44.165110Z"
    },
    "papermill": {
     "duration": 0.017271,
     "end_time": "2024-04-08T17:24:44.167927",
     "exception": false,
     "start_time": "2024-04-08T17:24:44.150656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@log_time\n",
    "def preparing_data(df):\n",
    "    train_df = df.groupby('eeg_id')[['spectrogram_id','spectrogram_label_offset_seconds']].agg({\n",
    "        'spectrogram_id':'first',\n",
    "        'spectrogram_label_offset_seconds':'min'\n",
    "    })\n",
    "    train_df.columns = ['spectrogram_id','min']\n",
    "\n",
    "    aux = df.groupby('eeg_id')[['spectrogram_id','spectrogram_label_offset_seconds']].agg({\n",
    "        'spectrogram_label_offset_seconds':'max'\n",
    "    })\n",
    "    train_df['max'] = aux\n",
    "\n",
    "    aux = df.groupby('eeg_id')[['patient_id']].agg('first')\n",
    "    train_df['patient_id'] = aux\n",
    "\n",
    "    aux = df.groupby('eeg_id')[label_cols].agg('sum')\n",
    "    for label in label_cols:\n",
    "        train_df[label] = aux[label].values\n",
    "        \n",
    "    y_data = train_df[label_cols].values\n",
    "    y_data = y_data / y_data.sum(axis=1,keepdims=True)\n",
    "    train_df[label_cols] = y_data\n",
    "\n",
    "    aux = df.groupby('eeg_id')[['expert_consensus']].agg('first')\n",
    "    train_df['target'] = aux\n",
    "\n",
    "    train_df = train_df.reset_index()\n",
    "    return train_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "941ece0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T17:24:44.183245Z",
     "iopub.status.busy": "2024-04-08T17:24:44.182537Z",
     "iopub.status.idle": "2024-04-08T17:24:44.187657Z",
     "shell.execute_reply": "2024-04-08T17:24:44.186842Z"
    },
    "papermill": {
     "duration": 0.014627,
     "end_time": "2024-04-08T17:24:44.189459",
     "exception": false,
     "start_time": "2024-04-08T17:24:44.174832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_wavelet_features(signal, wavelet='db4', level=5):\n",
    "    coeffs = pywt.wavedec(signal, wavelet, level=level)\n",
    "    # 从小波系数中提取特征而不是直接用小波系数，因为有不规则大小。\n",
    "    features = []\n",
    "    for coeff in coeffs:\n",
    "        features.extend([np.mean(coeff), np.std(coeff)])\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81959d33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T17:24:44.204657Z",
     "iopub.status.busy": "2024-04-08T17:24:44.204404Z",
     "iopub.status.idle": "2024-04-08T17:24:44.216089Z",
     "shell.execute_reply": "2024-04-08T17:24:44.215273Z"
    },
    "papermill": {
     "duration": 0.021473,
     "end_time": "2024-04-08T17:24:44.217941",
     "exception": false,
     "start_time": "2024-04-08T17:24:44.196468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@log_time\n",
    "def loading_parquet(train_df, config = config, READ_SPEC_FILES = True,READ_EEG_SPEC_FILES = True,wavelet = 'None'):\n",
    "    # paths_spectograms = glob(paths.TRAIN_SPECTOGRAMS + \"*.parquet\")\n",
    "    paths_spectrograms = glob(str(paths.TRAIN_SPECTROGRAMS / \"*.parquet\"))\n",
    "    print(f'There are {len(paths_spectrograms)} spectrogram parquets in total path')\n",
    "\n",
    "    if READ_SPEC_FILES:    \n",
    "        all_spectrograms = {}\n",
    "        all_wavelet_spectrograms = {}\n",
    "        spectogram_ids = train_df['spectrogram_id'].unique()\n",
    "        print(f'There are {len(spectogram_ids)} spectrogram parquets in this training process')\n",
    "#         for spec_id in tqdm(spectogram_ids):\n",
    "        for file_path in tqdm(paths_spectrograms):\n",
    "#             file_path = f\"{paths.TRAIN_SPECTROGRAMS}/{spec_id}.parquet\"\n",
    "            aux = pd.read_parquet(file_path)\n",
    "            spec_arr = aux.fillna(0).values[:, 1:].T.astype(\"float32\")  # (Hz, Time) = (400, 300)\n",
    "            wavelet_features = np.array([compute_wavelet_features(row, wavelet=wavelet) for row in spec_arr])\n",
    "            name = int(file_path.split(\"/\")[-1].split('.')[0])\n",
    "            # all_spectrograms[name] = aux.iloc[:,1:].values  \n",
    "            all_spectrograms[name] = aux.fillna(0).iloc[:,1:].values.astype(\"float32\")\n",
    "            all_wavelet_spectrograms[name] = wavelet_features\n",
    "            del aux\n",
    "            del wavelet_features\n",
    "        os.makedirs(os.path.dirname(paths.PRE_LOADED_SPECTROGRAMS), exist_ok=True)\n",
    "        os.makedirs(os.path.dirname(paths.PRE_LOADED_Wavelets), exist_ok=True)\n",
    "        np.save(paths.PRE_LOADED_SPECTROGRAMS, all_spectrograms, allow_pickle=True)\n",
    "        np.save(paths.PRE_LOADED_Wavelets, all_wavelet_spectrograms, allow_pickle=True)\n",
    "#         del all_spectrograms\n",
    "#         del all_wavelet_spectrograms\n",
    "    else:\n",
    "        all_spectrograms = np.load(paths.PRE_LOADED_SPECTROGRAMS, allow_pickle=True).item()\n",
    "        all_wavelet_spectrograms = np.load(paths.PRE_LOADED_Wavelets, allow_pickle=True).item()\n",
    "        \n",
    "    if config.VISUALIZE:\n",
    "        idx = np.random.randint(0,len(paths_spectrograms))\n",
    "        spectrogram_path = paths_spectrograms[idx]\n",
    "        plot_spectrogram(spectrogram_path)\n",
    "\n",
    "    # Read EEG Spectrograms\n",
    "#     # paths_eegs = glob(paths.TRAIN_EEGS + \"*.parquet\")\n",
    "#     paths_eegs = glob(str(paths.TRAIN_EEGS / \"*.parquet\"))\n",
    "#     print(f'There are {len(paths_eegs)} EEG spectrograms in total path')\n",
    "#     if READ_EEG_SPEC_FILES:\n",
    "#         all_eegs = {}\n",
    "#         eeg_ids = train_df['eeg_id'].unique()\n",
    "#         print(f'There are {len(eeg_ids)} EEG spectrograms in this training path')\n",
    "#         for file_path in tqdm(paths_eegs):\n",
    "# #         for eeg_id in tqdm(eeg_ids):\n",
    "#             file_path = f\"{paths.TRAIN_EEGS}/{eeg_id}.parquet\"\n",
    "#             eeg_spectogram =  pd.read_parquet(file_path)\n",
    "#             all_eegs[eeg_id] = eeg_spectogram\n",
    "#             del eeg_spectogram\n",
    "#         os.makedirs(os.path.dirname(paths.PRE_LOADED_EEGS), exist_ok=True)\n",
    "#         np.save(paths.PRE_LOADED_EEGS, all_eegs, allow_pickle=True)\n",
    "#         del all_eegs\n",
    "#     else:\n",
    "#         all_eegs = np.load(paths.PRE_LOADED_EEGS, allow_pickle=True).item()\n",
    "    return all_spectrograms,all_wavelet_spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf06051c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T17:24:44.233212Z",
     "iopub.status.busy": "2024-04-08T17:24:44.232920Z",
     "iopub.status.idle": "2024-04-08T17:25:55.278814Z",
     "shell.execute_reply": "2024-04-08T17:25:55.277753Z"
    },
    "papermill": {
     "duration": 71.062862,
     "end_time": "2024-04-08T17:25:55.287971",
     "exception": false,
     "start_time": "2024-04-08T17:24:44.225109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log file path: /kaggle/working/new_version_training_record.log\n",
      "seed_everything took 0.0024 seconds.\n",
      "Train cataframe shape is: (106800, 15)\n",
      "Labels: ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n",
      "       eeg_id  eeg_sub_id  eeg_label_offset_seconds  spectrogram_id  \\\n",
      "0  1628180742           0                       0.0          353733   \n",
      "1  1628180742           1                       6.0          353733   \n",
      "2  1628180742           2                       8.0          353733   \n",
      "3  1628180742           3                      18.0          353733   \n",
      "4  1628180742           4                      24.0          353733   \n",
      "\n",
      "   spectrogram_sub_id  spectrogram_label_offset_seconds    label_id  \\\n",
      "0                   0                               0.0   127492639   \n",
      "1                   1                               6.0  3887563113   \n",
      "2                   2                               8.0  1142670488   \n",
      "3                   3                              18.0  2718991173   \n",
      "4                   4                              24.0  3080632009   \n",
      "\n",
      "   patient_id expert_consensus  seizure_vote  lpd_vote  gpd_vote  lrda_vote  \\\n",
      "0       42516          Seizure             3         0         0          0   \n",
      "1       42516          Seizure             3         0         0          0   \n",
      "2       42516          Seizure             3         0         0          0   \n",
      "3       42516          Seizure             3         0         0          0   \n",
      "4       42516          Seizure             3         0         0          0   \n",
      "\n",
      "   grda_vote  other_vote  \n",
      "0          0           0  \n",
      "1          0           0  \n",
      "2          0           0  \n",
      "3          0           0  \n",
      "4          0           0  \n",
      "preparing_data took 0.0689 seconds.\n",
      "Train non-overlapp eeg_id shape: (17089, 12)\n",
      "   eeg_id  spectrogram_id     min     max  patient_id  seizure_vote  lpd_vote  \\\n",
      "0  568657       789577333     0.0    16.0       20654           0.0  0.000000   \n",
      "1  582999      1552638400     0.0    38.0       20230           0.0  0.857143   \n",
      "2  642382        14960202  1008.0  1032.0        5955           0.0  0.000000   \n",
      "3  751790       618728447   908.0   908.0       38549           0.0  0.000000   \n",
      "4  778705        52296320     0.0     0.0       40955           0.0  0.000000   \n",
      "\n",
      "   gpd_vote  lrda_vote  grda_vote  other_vote target  \n",
      "0      0.25   0.000000   0.166667    0.583333  Other  \n",
      "1      0.00   0.071429   0.000000    0.071429    LPD  \n",
      "2      0.00   0.000000   0.000000    1.000000  Other  \n",
      "3      1.00   0.000000   0.000000    0.000000    GPD  \n",
      "4      0.00   0.000000   0.000000    1.000000  Other  \n",
      "There are 11138 spectrogram parquets in total path\n",
      "loading_parquet took 70.4889 seconds.\n",
      "Loading basic dataset success!!!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "overall_start_time = time.time()\n",
    "print(f\"Log file path: {log_filename.absolute()}\")\n",
    "logging.info('--------------------------------------------------')\n",
    "logging.info(f'Into loading stage')\n",
    "\n",
    "target_preds = [x + \"_pred\" for x in ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']]\n",
    "label_to_num = {'Seizure': 0, 'LPD': 1, 'GPD': 2, 'LRDA': 3, 'GRDA': 4, 'Other':5}\n",
    "num_to_label = {v: k for k, v in label_to_num.items()}\n",
    "seed_everything(config.SEED)\n",
    "\n",
    "df = pd.read_csv(paths.TRAIN_CSV)\n",
    "label_cols = df.columns[-6:]\n",
    "print(f\"Train cataframe shape is: {df.shape}\")\n",
    "print(f\"Labels: {list(label_cols)}\")\n",
    "print(df.head())\n",
    "\n",
    "#处理train_df，eeg_id,只保留第一个spectrogram_id，min及max spec offset，第一个patient_id等\n",
    "train_df = preparing_data(df)\n",
    "print('Train non-overlapp eeg_id shape:', train_df.shape )\n",
    "print(train_df.head())\n",
    "train_df.to_csv('./local_train_df.csv', index=False)\n",
    "\n",
    "\n",
    "# train_df = pd.read_csv('/kaggle/input/version1-dataset-singlenpy/local_train_df.csv')\n",
    "# logging.info(f'Into loading stage: combine wavelet feature into X')\n",
    "logging.info(f'Into loading stage: loading single npy from local file')\n",
    "all_spectrograms,all_wavelet_spectrograms = loading_parquet(train_df, config = config, READ_SPEC_FILES = False,READ_EEG_SPEC_FILES = False,wavelet='db1')\n",
    "# loading_parquet(train_df, config = config, READ_SPEC_FILES = True,READ_EEG_SPEC_FILES = True,wavelet='db1')\n",
    "\n",
    "logging.info(f'Loading basic dataset success!!!')\n",
    "print('Loading basic dataset success!!!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15d4a43c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T17:25:55.304158Z",
     "iopub.status.busy": "2024-04-08T17:25:55.303852Z",
     "iopub.status.idle": "2024-04-08T17:25:55.383689Z",
     "shell.execute_reply": "2024-04-08T17:25:55.382680Z"
    },
    "papermill": {
     "duration": 0.090523,
     "end_time": "2024-04-08T17:25:55.386080",
     "exception": false,
     "start_time": "2024-04-08T17:25:55.295557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold\n",
      "0.0    3418\n",
      "1.0    3418\n",
      "2.0    3418\n",
      "3.0    3418\n",
      "4.0    3417\n",
      "dtype: int64\n",
      "----------------------------------------------------------------------------------------------------\n",
      "   eeg_id  spectrogram_id     min     max  patient_id  seizure_vote  lpd_vote  \\\n",
      "0  568657       789577333     0.0    16.0       20654           0.0  0.000000   \n",
      "1  582999      1552638400     0.0    38.0       20230           0.0  0.857143   \n",
      "2  642382        14960202  1008.0  1032.0        5955           0.0  0.000000   \n",
      "3  751790       618728447   908.0   908.0       38549           0.0  0.000000   \n",
      "4  778705        52296320     0.0     0.0       40955           0.0  0.000000   \n",
      "\n",
      "   gpd_vote  lrda_vote  grda_vote  other_vote target  fold  \n",
      "0      0.25   0.000000   0.166667    0.583333  Other   4.0  \n",
      "1      0.00   0.071429   0.000000    0.071429    LPD   1.0  \n",
      "2      0.00   0.000000   0.000000    1.000000  Other   4.0  \n",
      "3      1.00   0.000000   0.000000    0.000000    GPD   2.0  \n",
      "4      0.00   0.000000   0.000000    1.000000  Other   0.0  \n",
      "X shape: torch.Size([128, 256, 8])\n",
      "y shape: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "# Validation \n",
    "gkf = GroupKFold(n_splits=config.FOLDS)\n",
    "for fold, (train_index, valid_index) in enumerate(gkf.split(train_df, train_df.target, train_df.patient_id)):\n",
    "    train_df.loc[valid_index, \"fold\"] = int(fold)\n",
    "\n",
    "print(train_df.groupby('fold').size()), sep()\n",
    "print(train_df.head())\n",
    "\n",
    "train_df = train_df[train_df['fold'] == 0]\n",
    "\n",
    "logging.info(f'training based on model: efficientnet_b4')\n",
    "logging.info(f'Feature: without eegs, only specs and wavelets')\n",
    "train_dataset = CustomDataset(train_df, config, mode=\"train\", \n",
    "                              specs=all_spectrograms,wavelets_spectrograms = all_wavelet_spectrograms)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.BATCH_SIZE_TRAIN,\n",
    "    shuffle=False,\n",
    "    num_workers=config.NUM_WORKERS, pin_memory=True, drop_last=True\n",
    ")\n",
    "X, y = train_dataset[0]\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4deb8ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T17:25:55.403031Z",
     "iopub.status.busy": "2024-04-08T17:25:55.402715Z",
     "iopub.status.idle": "2024-04-08T17:25:55.408587Z",
     "shell.execute_reply": "2024-04-08T17:25:55.407707Z"
    },
    "papermill": {
     "duration": 0.016532,
     "end_time": "2024-04-08T17:25:55.410547",
     "exception": false,
     "start_time": "2024-04-08T17:25:55.394015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # if config.VISUALIZE:\n",
    "# #     ROWS = 2\n",
    "# #     COLS = 3\n",
    "# #     for (X, y) in train_loader:\n",
    "# #         plt.figure(figsize=(20,8))\n",
    "# #         for row in range(ROWS):\n",
    "# #             for col in range(COLS):\n",
    "# #                 plt.subplot(ROWS, COLS, row*COLS + col+1)\n",
    "# #                 t = y[row*COLS + col]\n",
    "# #                 img = X[row*COLS + col, :, :, 0]\n",
    "# #                 mn = img.flatten().min()\n",
    "# #                 mx = img.flatten().max()\n",
    "# #                 img = (img-mn)/(mx-mn)\n",
    "# #                 plt.imshow(img)\n",
    "# #                 tars = f'[{t[0]:0.2f}'\n",
    "# #                 for s in t[1:]:\n",
    "# #                     tars += f', {s:0.2f}'\n",
    "# #                 eeg = train_df.eeg_id.values[row*config.BATCH_SIZE_TRAIN + row*COLS + col]\n",
    "# #                 plt.title(f'EEG = {eeg}\\nTarget = {tars}',size=12)\n",
    "# #                 plt.yticks([])\n",
    "# #                 plt.ylabel('Frequencies (Hz)',size=14)\n",
    "# #                 plt.xlabel('Time (sec)',size=16)\n",
    "# #         plt.show()\n",
    "# #         break\n",
    "\n",
    "#dynamic learning rate\n",
    "# EPOCHS = config.EPOCHS\n",
    "# BATCHES = len(train_loader)\n",
    "# steps = []\n",
    "# lrs = []\n",
    "# optim_lrs = []\n",
    "# model = CustomModel(config)\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "# scheduler = OneCycleLR(\n",
    "#     optimizer,\n",
    "#     max_lr=1e-3,\n",
    "#     epochs=config.EPOCHS,\n",
    "#     steps_per_epoch=len(train_loader),\n",
    "#     pct_start=0.05,\n",
    "#     anneal_strategy=\"cos\",\n",
    "#     final_div_factor=100,\n",
    "# )\n",
    "# for epoch in range(EPOCHS):\n",
    "#     for batch in range(BATCHES):\n",
    "#         scheduler.step()\n",
    "#         lrs.append(scheduler.get_last_lr()[0])\n",
    "#         steps.append(epoch * BATCHES + batch)\n",
    "\n",
    "# max_lr = max(lrs)\n",
    "# min_lr = min(lrs)\n",
    "# print(f\"Maximum LR: {max_lr} | Minimum LR: {min_lr}\")\n",
    "# plt.figure()\n",
    "# plt.plot(steps, lrs, label='OneCycle')\n",
    "# plt.ticklabel_format(axis='y', style='sci', scilimits=(0,0))\n",
    "# plt.xlabel(\"Step\")\n",
    "# plt.ylabel(\"Learning Rate\")\n",
    "# plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81db4c08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T17:25:55.427108Z",
     "iopub.status.busy": "2024-04-08T17:25:55.426795Z",
     "iopub.status.idle": "2024-04-08T17:36:00.238867Z",
     "shell.execute_reply": "2024-04-08T17:36:00.237940Z"
    },
    "papermill": {
     "duration": 604.822462,
     "end_time": "2024-04-08T17:36:00.240740",
     "exception": false,
     "start_time": "2024-04-08T17:25:55.418278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ea256dd8813416a8a15ff9f16b62edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/36.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   1%|          | 1/106 [00:03<06:09,  3.52s/train_batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/106] Elapsed 0m 3s (remain 6m 10s) Loss: 1.5288 Grad: 376490.7500  LR: 0.00004249  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  20%|█▉        | 21/106 [00:41<02:39,  1.87s/train_batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][20/106] Elapsed 0m 41s (remain 2m 46s) Loss: 1.2941 Grad: 159705.8281  LR: 0.00077951  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  39%|███▊      | 41/106 [01:18<02:01,  1.87s/train_batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][40/106] Elapsed 1m 18s (remain 2m 4s) Loss: 1.2005 Grad: 119761.8984  LR: 0.00099687  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  58%|█████▊    | 61/106 [01:56<01:24,  1.88s/train_batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][60/106] Elapsed 1m 56s (remain 1m 25s) Loss: 1.1516 Grad: 84987.2266  LR: 0.00097279  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  76%|███████▋  | 81/106 [02:34<00:48,  1.92s/train_batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][80/106] Elapsed 2m 34s (remain 0m 47s) Loss: 1.0973 Grad: 93521.9609  LR: 0.00092602  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  95%|█████████▌| 101/106 [03:11<00:09,  1.89s/train_batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][100/106] Elapsed 3m 11s (remain 0m 9s) Loss: 1.0752 Grad: 137919.8438  LR: 0.00085881  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 106/106 [03:21<00:00,  1.90s/train_batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][105/106] Elapsed 3m 21s (remain 0m 0s) Loss: 1.0660 Grad: 78718.1953  LR: 0.00083917  \n",
      "train_epoch took 201.1664 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   1%|          | 1/106 [00:01<03:17,  1.88s/train_batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][0/106] Elapsed 0m 1s (remain 3m 18s) Loss: 0.8502 Grad: 172788.3906  LR: 0.00083512  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  20%|█▉        | 21/106 [00:39<02:39,  1.88s/train_batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][20/106] Elapsed 0m 39s (remain 2m 41s) Loss: 0.8949 Grad: 90659.8438  LR: 0.00074629  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  39%|███▊      | 41/106 [01:17<02:03,  1.90s/train_batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][40/106] Elapsed 1m 17s (remain 2m 3s) Loss: 0.8866 Grad: 81078.8984  LR: 0.00064565  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  58%|█████▊    | 61/106 [01:55<01:26,  1.92s/train_batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][60/106] Elapsed 1m 55s (remain 1m 25s) Loss: 0.8585 Grad: 70056.7578  LR: 0.00053802  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  76%|███████▋  | 81/106 [02:33<00:47,  1.89s/train_batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][80/106] Elapsed 2m 33s (remain 0m 47s) Loss: 0.8230 Grad: 66633.8984  LR: 0.00042858  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  95%|█████████▌| 101/106 [03:11<00:09,  1.90s/train_batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][100/106] Elapsed 3m 11s (remain 0m 9s) Loss: 0.8127 Grad: 62465.3828  LR: 0.00032257  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 106/106 [03:20<00:00,  1.90s/train_batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [2][105/106] Elapsed 3m 20s (remain 0m 0s) Loss: 0.8079 Grad: 72295.4922  LR: 0.00029721  \n",
      "train_epoch took 200.9976 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   1%|          | 1/106 [00:01<03:29,  2.00s/train_batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][0/106] Elapsed 0m 1s (remain 3m 29s) Loss: 0.5378 Grad: 118803.9219  LR: 0.00029221  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  20%|█▉        | 21/106 [00:39<02:41,  1.90s/train_batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][20/106] Elapsed 0m 39s (remain 2m 41s) Loss: 0.6883 Grad: 86146.9062  LR: 0.00019823  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  39%|███▊      | 41/106 [01:17<02:02,  1.89s/train_batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][40/106] Elapsed 1m 17s (remain 2m 3s) Loss: 0.6655 Grad: 76573.3672  LR: 0.00011875  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  58%|█████▊    | 61/106 [01:55<01:25,  1.90s/train_batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][60/106] Elapsed 1m 55s (remain 1m 25s) Loss: 0.6322 Grad: 74454.9688  LR: 0.00005757  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  76%|███████▋  | 81/106 [02:33<00:47,  1.89s/train_batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][80/106] Elapsed 2m 33s (remain 0m 47s) Loss: 0.6077 Grad: 78329.7031  LR: 0.00001764  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  95%|█████████▌| 101/106 [03:11<00:09,  1.90s/train_batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][100/106] Elapsed 3m 11s (remain 0m 9s) Loss: 0.5993 Grad: 49080.3945  LR: 0.00000088  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 106/106 [03:20<00:00,  1.89s/train_batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3][105/106] Elapsed 3m 20s (remain 0m 0s) Loss: 0.5947 Grad: 67324.6484  LR: 0.00000043  \n",
      "train_epoch took 200.8633 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loop_full_data took 604.8050 seconds.\n"
     ]
    }
   ],
   "source": [
    "if not config.TRAIN_FULL_DATA:\n",
    "    oof_df = pd.DataFrame()\n",
    "    for fold in range(config.FOLDS):\n",
    "        if fold in [0, 1, 2, 3, 4]:\n",
    "            _oof_df = train_loop(train_df, fold,)\n",
    "            oof_df = pd.concat([oof_df, _oof_df])\n",
    "            logging.info(f\"========== Fold {fold} result: {get_result(_oof_df)} ==========\")\n",
    "            print(f\"========== Fold {fold} result: {get_result(_oof_df)} ==========\")\n",
    "    oof_df = oof_df.reset_index(drop=True)\n",
    "    logging.info(f\"========== CV: {get_result(oof_df)} ==========\")\n",
    "    logging.info(f\"----------------------------------------------------------------------------------\")\n",
    "    # oof_df.to_csv(paths.OUTPUT_DIR + '/oof_df.csv', index=False)\n",
    "    oof_df.to_csv(os.path.join(paths.OUTPUT_DIR, 'oof_df.csv'), index=False)\n",
    "else:\n",
    "    train_loop_full_data(train_df)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 7469972,
     "sourceId": 59093,
     "sourceType": "competition"
    },
    {
     "datasetId": 4749606,
     "sourceId": 8053443,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 692.514474,
   "end_time": "2024-04-08T17:36:03.120705",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-08T17:24:30.606231",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01a22ca629eb4c66a198c94d821890cf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "245203c9ca194d9bbd4922259d35a594": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3619051e7da94d0ba2abf2bf8ba7dba7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3721a7fecc764fd89109973a9410678a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5465ada953a14c6288a9d4a471061a8f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6ea256dd8813416a8a15ff9f16b62edd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_aba2385569004c01868be0a77b4deda6",
        "IPY_MODEL_7c68683f785a4395a6a1268a8cfd2d2d",
        "IPY_MODEL_d0f3b862f07e460aaa02229f2de5913a"
       ],
       "layout": "IPY_MODEL_c7d80a6cfb5546ceae0acf958d0d20b5"
      }
     },
     "7c68683f785a4395a6a1268a8cfd2d2d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5465ada953a14c6288a9d4a471061a8f",
       "max": 36757206.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_245203c9ca194d9bbd4922259d35a594",
       "value": 36757206.0
      }
     },
     "a710f175a52d4a18818dc3ef9fce04a7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "aba2385569004c01868be0a77b4deda6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3619051e7da94d0ba2abf2bf8ba7dba7",
       "placeholder": "​",
       "style": "IPY_MODEL_a710f175a52d4a18818dc3ef9fce04a7",
       "value": "model.safetensors: 100%"
      }
     },
     "c7d80a6cfb5546ceae0acf958d0d20b5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d0f3b862f07e460aaa02229f2de5913a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_01a22ca629eb4c66a198c94d821890cf",
       "placeholder": "​",
       "style": "IPY_MODEL_3721a7fecc764fd89109973a9410678a",
       "value": " 36.8M/36.8M [00:00&lt;00:00, 122MB/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
